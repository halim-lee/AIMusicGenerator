{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Project_workbook_classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzXloeN6jjLd"
      },
      "source": [
        "# Project File - APS360 Team 25\n",
        "Divided into the following section: \n",
        "# \n",
        "1) Library imports\n",
        "2) Data imports\n",
        "3) Model architecture definition\n",
        "4) Training function definition\n",
        "5) Model training\n",
        "6) Model testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XAQ-54EjjLe"
      },
      "source": [
        "## Library imports \n",
        "(Place all library imports here)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTJQZVdDjjLf"
      },
      "source": [
        "#import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import time # Tracking model training time."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T67zGCXWnDV9",
        "outputId": "78f5f963-1376-40cb-d940-467235db0943",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Install mido for Data importing\n",
        "!pip install mido;\n",
        "\n",
        "import mido\n",
        "from mido import MidiFile, Message, MidiTrack, MetaMessage\n",
        "import os\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mido\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/0a/81beb587b1ae832ea6a1901dc7c6faa380e8dd154e0a862f0a9f3d2afab9/mido-1.2.9-py2.py3-none-any.whl (52kB)\n",
            "\r\u001b[K     |██████▎                         | 10kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 20kB 17.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 30kB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 40kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 51kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 3.1MB/s \n",
            "\u001b[?25hInstalling collected packages: mido\n",
            "Successfully installed mido-1.2.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Iv0dOlJpBsE",
        "outputId": "126a5564-8cd2-489b-b3a4-6e0fa2701216",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#mount googledrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# location on Google Drive\n",
        "master_path = '/content/gdrive/My Drive/APS360/Project/'\n",
        "\n",
        "#Set working directory if required:\n",
        "%cd /content/gdrive/My\\ Drive/APS360/Project/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive/APS360/Project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGUNjsjljjLl"
      },
      "source": [
        "## Data imports\n",
        "#### MIDI reading functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVVI_Cc_jjLm"
      },
      "source": [
        "def CountTracks(directory):          #Count files and tracks in folder\n",
        "    trackCount = 0\n",
        "    fileCount = 0\n",
        "    for file in os.listdir(directory):\n",
        "        if file.endswith(\".midi\"):\n",
        "            fileCount += 1\n",
        "            midiDir = MidiFile(directory+\"/\"+file)\n",
        "            for track in midiDir.tracks:\n",
        "                trackCount += 1\n",
        "    print(fileCount+\" files\")\n",
        "    print(trackCount+\" tracks\")\n",
        "\n",
        "    \n",
        "def PrintMessages(mid):                # print midi messages\n",
        "    for i, track in enumerate(mid.tracks):\n",
        "        print('Track {}: {}'.format(i, track.name))\n",
        "        for msg in track:\n",
        "            print(msg)\n",
        "\n",
        "            \n",
        "def PrintSomeMessages(mid):             #print first 200 midi messages\n",
        "    track = mid.tracks[1]\n",
        "    for i,msg in enumerate(track):\n",
        "        if i < 200:\n",
        "            print(msg)\n",
        "            \n",
        "def PrintMetaMessages(mid):             #print fmeta messages\n",
        "    track = mid.tracks[0]\n",
        "    for i,msg in enumerate(track):\n",
        "        print(msg)\n",
        "\n",
        "def cleanupMessages(mid):              #removes non-note messages by force\n",
        "    track = mid.tracks[1]\n",
        "    track2 = []\n",
        "    for msg in track:\n",
        "        if msg.type == \"note_on\":\n",
        "            track2.append(msg)\n",
        "    mid.tracks[1] = track2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlxYyJlvjjLp"
      },
      "source": [
        "#### MIDI to Numpy code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PwuX5ACjjLp"
      },
      "source": [
        "def Midi2NumpyNoSustain(mid):                                #converts to numpy array removing non-note messages\n",
        "    track = mid.tracks[1]                           #0th track only contains meta-messages, all notes on 1st track\n",
        "    notes = np.empty([0,4])\n",
        "    time = 0\n",
        "    for msg in track:\n",
        "        if msg.type == \"note_on\":                   # only count \"note\" messages - other inputs i.e. foot pedals are ignored\n",
        "            notes = np.append(notes,np.array([[msg.note, msg.velocity, msg.time + time, 0]]),axis=0)         # (note, velocity, time, sustain)\n",
        "            time = 0\n",
        "        else:\n",
        "            time += msg.time                        #adjust time when removing other messages\n",
        "    return notes\n",
        "\n",
        "\n",
        "def NumpyGetSustain(note):\n",
        "    notes = np.copy(note)\n",
        "    for i, msg in enumerate(notes):\n",
        "        if msg[1] > 0:                            # if velocity is not 0\n",
        "            j = 1\n",
        "            sustain = 0\n",
        "            while msg[0] != notes[i+j][0]:        # while note values are different\n",
        "                sustain += notes[i+j][2]\n",
        "                j += 1                            #search for next message with same note i.e. message telling that note was released\n",
        "            notes[i,3] = sustain + notes[i+j][2]\n",
        "    time = 0\n",
        "    for i, msg in enumerate(notes):\n",
        "        if msg[1] > 0:\n",
        "            notes[i,2] += time\n",
        "            time = 0\n",
        "        else:\n",
        "            time += msg[2]                        #adjust time\n",
        "    notes = notes[notes[:,1] > 0]                 #filter for notes with positive velocities (note presses)\n",
        "    return notes\n",
        "\n",
        "def NumpyNormalize(note, oneHot=False):                         #normalize all values to 0-1\n",
        "    notes = np.copy(note)\n",
        "    \n",
        "    if oneHot:\n",
        "        notes[:,12] /= 11\n",
        "        notes[:,13] /= 128\n",
        "        notes[:,14] /= 40000\n",
        "        notes[:,15] /= 40000\n",
        "    else:\n",
        "        notes[:,0] /= 128\n",
        "        notes[:,1] /= 128\n",
        "        notes[:,2] /= 40000\n",
        "        notes[:,3] /= 40000       \n",
        "    return notes\n",
        "\n",
        "def NumpyOneHot(note):\n",
        "    notes = np.copy(note)\n",
        "    oneHot = np.zeros([len(notes),16])\n",
        "    oneHot[:, 13:] = notes[:, 1:]\n",
        "    names = notes[:,0]\n",
        "    namesOct = names%12\n",
        "    oneHot[:,12] = (names-(namesOct))/12\n",
        "    \n",
        "    for i, name in enumerate(namesOct):\n",
        "        oneHot[i,name.astype(int)] = 1\n",
        "    \n",
        "    return oneHot\n",
        "\n",
        "def Midi2Numpy(path, oneHot=False): # full midi to numpy conversion\n",
        "    mid = MidiFile(path)\n",
        "    notes = Midi2NumpyNoSustain(mid)\n",
        "    cleanNotes = NumpyGetSustain(notes)\n",
        "    \n",
        "    if oneHot:\n",
        "        cleanNotes = NumpyOneHot(cleanNotes)\n",
        "    \n",
        "    normNotes = NumpyNormalize(cleanNotes, oneHot=oneHot)\n",
        "    return normNotes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwph1iNajjLs"
      },
      "source": [
        "#### Numpy to MIDI code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aG5_vp-jjLt"
      },
      "source": [
        "def NumpyDenormalize(note): # interpret all values from 0-1 to normal values\n",
        "    notes = np.copy(note)    \n",
        "    if notes.shape[1] == 16: # if encode as one-hot\n",
        "        notes[:,12] *= 11\n",
        "        notes[:,13] *= 128\n",
        "        notes[:,14] *= 40000\n",
        "        notes[:,15] *= 40000\n",
        "        \n",
        "        notes = NumpyEncode(notes) #encode back as original 4-variable format\n",
        "    else:\n",
        "        notes[:,0] *= 128\n",
        "        notes[:,1] *= 128\n",
        "        notes[:,2] *= 40000\n",
        "        notes[:,3] *= 40000       \n",
        "    return notes.astype(int)\n",
        "\n",
        "def NumpyEncode(note): # convert back from one-hot encoding\n",
        "    notes = np.copy(note)\n",
        "    encoded = np.zeros([len(notes),4])\n",
        "    encoded[:, 1:] = notes[:, 13:]\n",
        "    encoded[:, 0] = notes[:,12]*12\n",
        "    \n",
        "    for i in range(len(notes)):\n",
        "        encoded[i,0] += np.argmax(notes[i,:12])\n",
        "    \n",
        "    return encoded\n",
        "\n",
        "def NumpySequence(notes): # put all notes into a \"timeline\" i.e.: time values of [10, 20, 10, 30] become [10, 30, 40, 70]\n",
        "    sequenced = np.copy(notes)                      # this allows us to easily add vel=0 notes in any order since we can later sort them by time\n",
        "    for i, msg in enumerate(sequenced):\n",
        "        if i > 0:\n",
        "            sequenced[i,2] += sequenced[i-1,2]\n",
        "    return sequenced\n",
        "\n",
        "def NumpyAddOffNotes(sequenced): # add vel=0 notes from sustain into sequenced timeline\n",
        "    withOff = np.copy(sequenced)\n",
        "    for msg in sequenced:\n",
        "        offNote = np.array([[msg[0], 0, msg[2] + msg[3], 0]])\n",
        "        withOff = np.append(withOff, offNote, axis=0)\n",
        "    #withOff = np.sort(withOff,axis=0)\n",
        "    withOff = withOff[withOff[:,2].argsort()] # sort by time\n",
        "    return withOff\n",
        "\n",
        "def NumpyUnsequence(notes): # revert time value to \"time since last message\"\n",
        "    unsequenced = np.copy(notes)\n",
        "    for i, msg in reversed(list(enumerate(unsequenced))):\n",
        "        unsequenced[i,3] = 0\n",
        "        if i > 0:\n",
        "            unsequenced[i,2] -= unsequenced[i-1,2]\n",
        "    return unsequenced\n",
        "\n",
        "def Numpy2MidiDirect(array):    #make MIDI object from numpy\n",
        "    #Start with initializing a new Mido Track:\n",
        "    mid = MidiFile()\n",
        "    track0 = MidiTrack()\n",
        "    track1 = MidiTrack()\n",
        "    \n",
        "    track0.append(MetaMessage('set_tempo', tempo=500000, time=0)) #MetaMessages not necessary but are present in used files\n",
        "    track0.append(MetaMessage('time_signature', numerator=4, denominator=4, clocks_per_click=24, notated_32nd_notes_per_beat=8, time=0))\n",
        "    track0.append(MetaMessage('end_of_track', time=1))\n",
        "    \n",
        "    track1.append(Message('program_change', channel=0, program=0, time=0))\n",
        "    \n",
        "    for i,note in enumerate(array):         # Get the index and the note. Array must be int array\n",
        "        j = 1\n",
        "        track1.append(Message('note_on',note = array[i,0], velocity = array[i,1],time = array[i,2])) # Add the note to the track.\n",
        "\n",
        "    mid.tracks.append(track0)\n",
        "    mid.tracks.append(track1)\n",
        "    return mid\n",
        "\n",
        "def Numpy2Midi(notes, name): # full numpy to midi conversion, saving result to [name].midi\n",
        "    denorm = NumpyDenormalize(notes)\n",
        "    seq = NumpySequence(denorm)\n",
        "    off = NumpyAddOffNotes(seq)\n",
        "    unseq = NumpyUnsequence(off)\n",
        "    mid = Numpy2MidiDirect(unseq)\n",
        "    mid.save(name + \".midi\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZmupxvijjLv"
      },
      "source": [
        "#### Generatng tensor dataset from CSVs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGT7Y7KqjjLw"
      },
      "source": [
        "def Numpy2Dataset(notes,num=20,skip=10): # make list of sumpy arrays\n",
        "    samples = []\n",
        "    i = 0\n",
        "    while i+num <= len(notes):\n",
        "        samples.append(notes[i:i+num])\n",
        "        i += skip\n",
        "    return samples\n",
        "\n",
        "def SampleAllNumpy(dataPath): # generate samples from all saved CSVs\n",
        "    allSamples = []\n",
        "\n",
        "    for i,f in enumerate(os.listdir(dataPath)):\n",
        "        notes = np.genfromtxt(dataPath+f, delimiter=',')\n",
        "        allSamples += Numpy2Dataset(notes)\n",
        "        if i % 100 == 0:\n",
        "            print(i)\n",
        "    \n",
        "    return allSamples\n",
        "\n",
        "def SaveSamplesTensor(samples, outputPath): # save tensor\n",
        "    tens = torch.Tensor(samples)\n",
        "    torch.save(samples, outputPath+\"Notes_Dataset.pt\")\n",
        "    return tens   \n",
        "\n",
        "def SaveAllSamples(dataPath, outputPath): # save dataset tensor\n",
        "    samples = SampleAllNumpy(dataPath)\n",
        "    SaveSamplesTensor(samples, outputPath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0zg4NX2jjLz"
      },
      "source": [
        "#### Bulk data conversion code - COMMENT OUT IF NOT IN USE!!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qRrA4ZkjjL0"
      },
      "source": [
        "#SaveAllSamples(\"data/numpy_files/\",\"data/\") #save all into tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bA3gNjzkjjL2"
      },
      "source": [
        "# IMPORTANT: COMMENT OUT IF NOT IN USE TO AVOID ACCIDENTS!!!!!!!\n",
        "\n",
        "# Getting CSVs from MIDI data and processed data from CSVs\n",
        "# Processed MIDI does not contain program messages and so are a good measure of what output SHOULD look like in a perfect world\n",
        "\n",
        "# dataPath = \"data/MIDI_files_original/\"\n",
        "# outputPath = \"data/numpy_files/\"\n",
        "# processedPath = \"data/MIDI_files_processed/\"\n",
        "\n",
        "# for i,f in enumerate(os.listdir(dataPath)):\n",
        "#     notes = Midi2Numpy(dataPath+f)\n",
        "#     np.savetxt(outputPath + \"MIDI_{:04d}.csv\".format(i),notes,delimiter=\",\")\n",
        "#     Numpy2Midi(notes, processedPath + \"MIDI_{:04d}\".format(i))\n",
        "    \n",
        "#     if i % 100 == 0:\n",
        "#         print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzbQ3B1FjjL6"
      },
      "source": [
        "# dataPath = \"data/numpy_files/\"  # one-hot encoding on CSVs\n",
        "# outputPath = \"data/numpy_onehot\"\n",
        "\n",
        "# for i,f in enumerate(os.listdir(dataPath)):\n",
        "#     notes = np.genfromtxt(dataPath+f, delimiter=',')\n",
        "#     notes = NumpyDenormalize(notes)\n",
        "#     notes = NumpyOneHot(notes)\n",
        "#     notes = NumpyNormalize(notes, oneHot=True)\n",
        "#     np.savetxt(outputPath + \"MIDI_{:04d}.csv\".format(i),notes,delimiter=\",\")\n",
        "#     if i % 100 == 0:\n",
        "#         print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HckUINzJjjL8"
      },
      "source": [
        "## Baseline Model Code\n",
        "#### getting available notes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yS_gJ_sljjL9"
      },
      "source": [
        "def GetAllNotesMajor(root):# Get all used notes in major scale of root=root\n",
        "    notes = []\n",
        "    intervals = [2,2,1,2,2,2,1]\n",
        "    \n",
        "    while root > 24: #bring down to lowest used octave\n",
        "        root -= 12\n",
        "    \n",
        "    n = root\n",
        "    notes.append(n)\n",
        "    while n < 84: #up to higherst used note\n",
        "        for i in intervals:\n",
        "            n += i\n",
        "            notes.append(n)   \n",
        "    return notes    \n",
        "\n",
        "\n",
        "def GetRangeMajor(notes, low, high): # Get all notes within range\n",
        "    lowIndex = notes.index(low)\n",
        "    highIndex = notes.index(high)\n",
        "    \n",
        "    return notes[lowIndex:highIndex+1]   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMKnIlZtjjL_"
      },
      "source": [
        "#### Piece Class\n",
        "##### represents whole output from all 4 voices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Egw2ow53jjMA"
      },
      "source": [
        "class Piece: # Entire baseline model compostion - composed of 4 voices soprano, alto, tenor, bass (SATB)\n",
        "    def __init__(self, barNum=16, root=60):# 16 bars in C major\n",
        "        self.root = root # root note\n",
        "        self.allNotes = GetAllNotesMajor(self.root) # all notes on major scale\n",
        "        self.barNum = barNum # number of bars\n",
        "        \n",
        "        self.soprano = Voice(self.allNotes,60,84,speed=8) # SATB\n",
        "        self.alto = Voice(self.allNotes,48,72)\n",
        "        self.tenor = Voice(self.allNotes,36,60)\n",
        "        self.bass = Voice(self.allNotes,24,48)\n",
        "          \n",
        "        self.notes = np.empty([0,4]) #notes output\n",
        "        \n",
        "        self.pieceChords = [] # chords\n",
        "        \n",
        "        self.chords = np.array([ # common classical C major chords\n",
        "            [ 0,  4,  7,  0],# I\n",
        "            [ 2,  5,  9,  2],# ii\n",
        "            [ 4,  7, 11,  4],# iii\n",
        "            [ 5,  9, 0,  5],# IV\n",
        "            [ 7, 11, 2,  7],# V\n",
        "            [ 9, 0, 4,  9],# vi\n",
        "            [11, 2, 5, 11],# vii dim\n",
        "            [ 2,  5,  9, 0],# ii7\n",
        "            [ 5,  9, 0, 4],# IVmaj7\n",
        "            [ 7, 11, 2, 5],# V7\n",
        "            [11, 2, 5, 9]])# vii7 half-dim\n",
        "        \n",
        "    def GenerateSoprano(self): # Generate soprano line\n",
        "        self.soprano.GenerateLine(self.soprano.speed*self.barNum)\n",
        "        \n",
        "    def GenerateAlto(self): # Generate alto line from chords\n",
        "        self.alto.GenerateChordLine(self.pieceChords)\n",
        "        \n",
        "    def GenerateTenor(self): # see alto\n",
        "        self.tenor.GenerateChordLine(self.pieceChords)\n",
        "        \n",
        "    def GenerateBass(self): # see alto\n",
        "        self.bass.GenerateChordLine(self.pieceChords)\n",
        "        \n",
        "        \n",
        "    \n",
        "    def ChooseChord(self, sopNote): # Choose a fitting chord for soprano note\n",
        "        while sopNote >= 12:\n",
        "            sopNote -= 12\n",
        "        \n",
        "        goodChords = np.empty([0,4])\n",
        "        \n",
        "        for chord in self.chords:\n",
        "            if (chord==sopNote).sum() > 0:\n",
        "                goodChords = np.append(goodChords,[chord],axis=0)\n",
        "        \n",
        "        chosenChord = goodChords[random.randint(0,len(goodChords)-1)]\n",
        "        chosenChord = np.sort(np.unique(chosenChord))\n",
        "        \n",
        "        i = 12\n",
        "        chordNotes = chosenChord\n",
        "        while i < 120:\n",
        "            chordNotes = np.append(chordNotes, chosenChord+i)\n",
        "            i += 12\n",
        "        \n",
        "        return(chordNotes)\n",
        "    \n",
        "    def GetChords(self): # select all chords in piece\n",
        "        for i, note in enumerate(self.soprano.notes):\n",
        "            if i % 2 == 0:\n",
        "                sopNote = note[0]\n",
        "                chord = self.ChooseChord(sopNote)\n",
        "                self.pieceChords.append(chord)\n",
        "                \n",
        "    def Normalize(self): # normalize all values to 0-1\n",
        "        for i, msg in enumerate(self.notes):\n",
        "            self.notes[i,0] = msg[0]/128\n",
        "            self.notes[i,1] = msg[1]/128\n",
        "            self.notes[i,2] = msg[2]/40000\n",
        "            self.notes[i,3] = msg[3]/40000\n",
        "                \n",
        "    def GenerateLines(self): # Generate all SATB lines and joins them - entire baseline model\n",
        "        self.GenerateSoprano()\n",
        "        self.GetChords()\n",
        "        self.GenerateAlto()\n",
        "        self.GenerateTenor()\n",
        "        self.GenerateBass()\n",
        "        self.joinLines()\n",
        "        self.OffsetTime(20)\n",
        "        self.Normalize()\n",
        "        \n",
        "        return self.notes\n",
        "        \n",
        "    def InsertLine(self, starting, inserted, startIndex, skipIndex): # join 2 lines\n",
        "        base = np.copy(starting)\n",
        "        ins = np.copy(inserted)\n",
        "        \n",
        "        for i,note in enumerate(ins):\n",
        "            base = np.insert(base, (i*skipIndex)+startIndex, [note], axis=0)\n",
        "            \n",
        "        return base\n",
        "        \n",
        "    def joinLines(self): # join all SATB lines\n",
        "        #self.notes = np.copy(self.soprano)\n",
        "        self.notes = self.InsertLine(self.soprano.notes, self.alto.notes, 1, 3)\n",
        "        self.notes = self.InsertLine(self.notes, self.tenor.notes, 2, 4)\n",
        "        self.notes = self.InsertLine(self.notes, self.bass.notes, 3, 5)\n",
        "        \n",
        "    def OffsetTime(self, maxChange): # adds random time offsets to make output sound more organic\n",
        "        for note in self.notes:\n",
        "            note[2] += random.randint(0,maxChange)\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsCKtb0UjjMD"
      },
      "source": [
        "#### Voice class\n",
        "##### Represents individual voices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2ftdfULjjME"
      },
      "source": [
        "class Voice: # individual voices\n",
        "    def __init__(self, allNotes, lowNote, highNote, jump=3, speed=4, time=4096, velocity=64):\n",
        "        self.range = GetRangeMajor(allNotes,lowNote,highNote) #available ntoes\n",
        "        self.jump = jump #maximum pitch interval between notes\n",
        "        self.speed = speed #note length i.e. 4 for quarter, 8 for eighth etc.\n",
        "        self.time = time #song speed\n",
        "        self.velocity = velocity #note volume\n",
        "        self.notes = np.empty([0,4]) #notes output\n",
        "        self.lowNote = lowNote # lowest note\n",
        "        self.highNote = highNote # highest note\n",
        "        self.allNotes = allNotes # all notes in scale\n",
        "            \n",
        "        self.duration = self.time / self.speed # time between notes\n",
        "        \n",
        "        \n",
        "    def RandomStartNote(self): # Generate Random first note (for soprano)\n",
        "        note = random.choice(self.range)\n",
        "        self.notes = np.append(self.notes,np.array([[note, self.velocity, 0, self.duration]]),axis=0)\n",
        "        \n",
        "        \n",
        "    def RandomJump(self): # Generate Random next note (for soprano)\n",
        "        lastNote = self.notes[len(self.notes)-1][0] # find last played note\n",
        "        lastIndex = self.range.index(lastNote)\n",
        "        \n",
        "        newIndex = -1\n",
        "        while newIndex < 0 or newIndex >= len(self.range): # stay in range\n",
        "            newIndex = lastIndex + random.randint(-self.jump,self.jump)\n",
        "            \n",
        "        newNote = self.range[newIndex]\n",
        "        self.notes = np.append(self.notes,np.array([[newNote, self.velocity, self.duration, self.duration]]),axis=0)\n",
        "        \n",
        "        \n",
        "    def GenerateLine(self, length): # Generate random line (for soprano)\n",
        "        self.RandomStartNote()\n",
        "        \n",
        "        for n in range(length-1):\n",
        "            self.RandomJump()\n",
        "            \n",
        "            \n",
        "    def clearNotes(self):\n",
        "        self.notes = np.empty([0,4])\n",
        "        \n",
        "    def GetChordNotes(self, chordNotes): # Get useful notes from all chord notes\n",
        "        chordNotes = chordNotes[chordNotes >= self.lowNote]\n",
        "        chordNotes = chordNotes[chordNotes <= self.highNote]\n",
        "        return chordNotes\n",
        "    \n",
        "    def ChooseStartChordNote(self, chordNotes): # Choose Random note in chord\n",
        "        note = random.choice(chordNotes)\n",
        "        self.notes = np.append(self.notes,np.array([[note, self.velocity, 0, self.duration]]),axis=0)\n",
        "        \n",
        "    def ChooseChordNote(self,chordNotes): # Choose suitable next note in chord\n",
        "        lastNote = self.notes[len(self.notes)-1][0] # find last played note\n",
        "        \n",
        "        chordNotes = chordNotes[chordNotes >= lastNote - (self.jump*2)]\n",
        "        chordNotes = chordNotes[chordNotes <= lastNote + (self.jump*2)]\n",
        "        newNote = random.choice(chordNotes)\n",
        "        \n",
        "        self.notes = np.append(self.notes,np.array([[newNote, self.velocity, 0, self.duration]]),axis=0)\n",
        "        \n",
        "    def GenerateChordLine(self, chords): # Generate A/T/B lines\n",
        "        \n",
        "        firstChord = self.GetChordNotes(chords[0])\n",
        "        self.ChooseStartChordNote(firstChord)\n",
        "        \n",
        "        for c in chords[1:]:\n",
        "            chord = self.GetChordNotes(c)\n",
        "            self.ChooseChordNote(chord)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSYLfWz-jjMK"
      },
      "source": [
        "## Model architecture definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e54Jnk9djjMK"
      },
      "source": [
        "Set the hyperparameters below:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bM6r1jkjjMN"
      },
      "source": [
        "#For LSTM: https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html #torch.nn.LSTM \n",
        "BATCH_SIZE = 64\n",
        "N_FEATURES = 16\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 2\n",
        "EMB_DIM = 128\n",
        "DROPOUT = 0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYJCrUv0ww-F"
      },
      "source": [
        "## Classification Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hvkryl71-FCX",
        "outputId": "4901fdfb-b509-4ac7-f951-de297f629fe5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "torch.manual_seed(1000) #Set the manual seed so that we get reproducible results.\n",
        "\n",
        "class LSTMEncoder(nn.Module):\n",
        "    def __init__(self, n_features, embedding_dim, num_layers, dropout):\n",
        "        super(LSTMEncoder, self).__init__()\n",
        "        self.n_features, self.num_layers =  n_features, num_layers\n",
        "        self.embedding_dim, self.hidden_size = (embedding_dim, 2 * embedding_dim)\n",
        "        self.lstm1 = nn.LSTM(n_features, self.hidden_size, num_layers, batch_first=True, \n",
        "                            dropout=dropout)\n",
        "        self.lstm2 = nn.LSTM(self.hidden_size, embedding_dim, num_layers, batch_first=True, \n",
        "                            dropout=dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm1(x)\n",
        "        out, (hidden, cell) = self.lstm2(out)\n",
        "        return out\n",
        "\n",
        "class LSTMDecoder(nn.Module):\n",
        "    def __init__(self, n_features, embedding_dim, num_layers, dropout):\n",
        "        super(LSTMDecoder, self).__init__()\n",
        "        self.n_features, self.num_layers =  n_features, num_layers\n",
        "        self.embedding_dim, self.hidden_size = (embedding_dim, 2 * embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, self.hidden_size, num_layers, batch_first=True,\n",
        "                            dropout=dropout)\n",
        "        self.fc = torch.nn.Linear(self.hidden_size, n_features)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        out = torch.sigmoid(self.fc(out))\n",
        "        return out\n",
        "\n",
        "\n",
        "class LSTMAutoEncoder(nn.Module):\n",
        "    def __init__(self, n_features, emb_dim, num_layers, dropout):\n",
        "        super(LSTMAutoEncoder, self).__init__()\n",
        "        self.name = \"LSTMAutoEncoder\"\n",
        "        self.encoder = LSTMEncoder(n_features, emb_dim, num_layers, dropout)\n",
        "        self.decoder = LSTMDecoder(n_features, emb_dim, num_layers, dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        sequence_length = x.shape[1]\n",
        "        encoded_x = self.encoder(x)\n",
        "        decoded_x = self.decoder(encoded_x)\n",
        "\n",
        "        return decoded_x\n",
        "\n",
        "print('Model class created succesfully')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model class created succesfully\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T63ukNsTjjMU"
      },
      "source": [
        "## Training function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9CtbU76jjMU"
      },
      "source": [
        "#To help us save the model easier...\n",
        "def get_model_name(name, batch_size, learning_rate, epoch):\n",
        "    \"\"\" Generate a name for the model consisting of all the hyperparameter values\n",
        "\n",
        "    Args:\n",
        "        config: Configuration object containing the hyperparameters\n",
        "    Returns:\n",
        "        path: A string with the hyperparameter name and value concatenated\n",
        "    \"\"\"\n",
        "    path = \"model_{0}_bs{1}_lr{2}_epoch{3}\".format(name,\n",
        "                                                   batch_size,\n",
        "                                                   learning_rate,\n",
        "                                                   epoch)\n",
        "    return path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGbi4_HyhPkP"
      },
      "source": [
        "def fit(model, train_loader, criterion, num_epochs, batch_size, learning_rate, class_regr):\n",
        "    losses = []\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(),\n",
        "                                 lr=learning_rate, \n",
        "                                 weight_decay=1e-5) # <-- Sometimes Adam converges faster than SGD\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, data in enumerate(train_loader):\n",
        "            excerpt = data[:,:-1] # Extracts all but the last row \n",
        "            true_note = data[:,-1]  # Extracts the last row (what we want it to predict)\n",
        "            out = model(excerpt)             # forward pass\n",
        "            last_out = out[:,-1,:]\n",
        "\n",
        "            if class_regr == \"classify\":\n",
        "                # Use classification for Note\n",
        "                pred = last_out[:,:12]\n",
        "                target = np.argmax(true_note[:,:12], axis=1)\n",
        "            else:\n",
        "                # Regression - Octave, Velocity, Time, Sustain\n",
        "                pred = last_out[:,12:]\n",
        "                target = true_note[:,12:]\n",
        "\n",
        "            loss = criterion(pred, target) # compute the total loss\n",
        "\n",
        "            loss.backward()               # backward pass (compute parameter updates)\n",
        "            optimizer.step()              # make the updates for each parameter\n",
        "            optimizer.zero_grad()         # a clean up step for PyTorch\n",
        "\n",
        "            losses.append(float(loss)/batch_size)             # compute *average* loss\n",
        "        \n",
        "        print('Epoch:{}, Loss:{:.4f}'.format(epoch+1, float(loss)))\n",
        "        #Checkpoint the model every epoch\n",
        "        model_path = get_model_name(model.name, batch_size, learning_rate, epoch) #Returns the model name for \n",
        "        #the save file.\n",
        "        torch.save(model.state_dict(), model_path) #Saves the current model with the weights.\n",
        "    return losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-g9mEM_hjjMb"
      },
      "source": [
        "def train(model_classify, model_regr, train_data, num_epochs=5, batch_size=64, learning_rate=1e-3):\n",
        "    torch.manual_seed(1000) #Fixed. Make sure we use this throughout...\n",
        "    criterion_classfy = nn.CrossEntropyLoss()\n",
        "    criterion_regr = nn.MSELoss()\n",
        "    \n",
        "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size)\n",
        "    \n",
        "    n = 0 # the number of iterations\n",
        "    start_time=time.time() #Start of training\n",
        "\n",
        "    # Classification - Note\n",
        "    loss_classify = fit(model_classify, train_loader, criterion_classfy,\n",
        "                        num_epochs, batch_size, learning_rate, class_regr=\"classify\")\n",
        "    # Regression - Octave, Velocity, Time, Sustain\n",
        "    loss_regr = fit(model_regr, train_loader, criterion_regr,\n",
        "                    num_epochs, batch_size, learning_rate, class_regr=\"regression\")\n",
        "\n",
        "    end_time= time.time()\n",
        "\n",
        "    return loss_classify, loss_regr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQqCUe3mjjMj"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGaCHzIUjjMk"
      },
      "source": [
        "# Load saved tensor dataset\n",
        "data = torch.load(r'/content/gdrive/My Drive/APS360/Project/Notes_Dataset.pt')\n",
        "\n",
        "# Prevent type errors\n",
        "data = torch.tensor(data).float()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EWE2ibcoIf6"
      },
      "source": [
        "# Split into smaller dataset for training\n",
        "train_data = data[:1000].detach().numpy()\n",
        "seq_data = np.zeros([len(train_data),20,16])\n",
        "\n",
        "# Convert numpy midi files into time series\n",
        "for i, sample in enumerate(train_data):\n",
        "    denorm = NumpyDenormalize(sample)\n",
        "    oneHot = NumpyOneHot(denorm)\n",
        "    seq_data[i] = NumpyNormalize(oneHot, oneHot=True)\n",
        "\n",
        "seq_data = np.double(seq_data)\n",
        "seq_data = torch.tensor(seq_data).float()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDKXrkkxrh0F",
        "outputId": "ca13fb9b-0090-4ff7-c812-510b184708e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Train the model\n",
        "model_classify = LSTMAutoEncoder(N_FEATURES, EMB_DIM, N_LAYERS, DROPOUT)\n",
        "model_regr = LSTMAutoEncoder(N_FEATURES, EMB_DIM, N_LAYERS, DROPOUT)\n",
        "loss_classify, loss_regr = train(model_classify, model_regr, seq_data, num_epochs=60, batch_size=BATCH_SIZE, learning_rate=0.001)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:1, Loss:2.3783\n",
            "Epoch:2, Loss:2.3328\n",
            "Epoch:3, Loss:2.3358\n",
            "Epoch:4, Loss:2.3376\n",
            "Epoch:5, Loss:2.3340\n",
            "Epoch:6, Loss:2.3339\n",
            "Epoch:7, Loss:2.3344\n",
            "Epoch:8, Loss:2.3345\n",
            "Epoch:9, Loss:2.3354\n",
            "Epoch:10, Loss:2.3343\n",
            "Epoch:11, Loss:2.3336\n",
            "Epoch:12, Loss:2.3325\n",
            "Epoch:13, Loss:2.3322\n",
            "Epoch:14, Loss:2.3325\n",
            "Epoch:15, Loss:2.3346\n",
            "Epoch:16, Loss:2.3334\n",
            "Epoch:17, Loss:2.3332\n",
            "Epoch:18, Loss:2.3330\n",
            "Epoch:19, Loss:2.3329\n",
            "Epoch:20, Loss:2.3345\n",
            "Epoch:21, Loss:2.3338\n",
            "Epoch:22, Loss:2.3327\n",
            "Epoch:23, Loss:2.3339\n",
            "Epoch:24, Loss:2.3331\n",
            "Epoch:25, Loss:2.3343\n",
            "Epoch:26, Loss:2.3324\n",
            "Epoch:27, Loss:2.3337\n",
            "Epoch:28, Loss:2.3339\n",
            "Epoch:29, Loss:2.3332\n",
            "Epoch:30, Loss:2.3339\n",
            "Epoch:31, Loss:2.3325\n",
            "Epoch:32, Loss:2.3330\n",
            "Epoch:33, Loss:2.3339\n",
            "Epoch:34, Loss:2.3330\n",
            "Epoch:35, Loss:2.3330\n",
            "Epoch:36, Loss:2.3325\n",
            "Epoch:37, Loss:2.3315\n",
            "Epoch:38, Loss:2.3326\n",
            "Epoch:39, Loss:2.3339\n",
            "Epoch:40, Loss:2.3324\n",
            "Epoch:41, Loss:2.3329\n",
            "Epoch:42, Loss:2.3335\n",
            "Epoch:43, Loss:2.3335\n",
            "Epoch:44, Loss:2.3325\n",
            "Epoch:45, Loss:2.3336\n",
            "Epoch:46, Loss:2.3332\n",
            "Epoch:47, Loss:2.3337\n",
            "Epoch:48, Loss:2.3329\n",
            "Epoch:49, Loss:2.3331\n",
            "Epoch:50, Loss:2.3326\n",
            "Epoch:51, Loss:2.3336\n",
            "Epoch:52, Loss:2.3336\n",
            "Epoch:53, Loss:2.3330\n",
            "Epoch:54, Loss:2.3329\n",
            "Epoch:55, Loss:2.3338\n",
            "Epoch:56, Loss:2.3347\n",
            "Epoch:57, Loss:2.3336\n",
            "Epoch:58, Loss:2.3326\n",
            "Epoch:59, Loss:2.3327\n",
            "Epoch:60, Loss:2.3329\n",
            "Epoch:1, Loss:0.0084\n",
            "Epoch:2, Loss:0.0089\n",
            "Epoch:3, Loss:0.0091\n",
            "Epoch:4, Loss:0.0086\n",
            "Epoch:5, Loss:0.0083\n",
            "Epoch:6, Loss:0.0087\n",
            "Epoch:7, Loss:0.0088\n",
            "Epoch:8, Loss:0.0088\n",
            "Epoch:9, Loss:0.0087\n",
            "Epoch:10, Loss:0.0088\n",
            "Epoch:11, Loss:0.0088\n",
            "Epoch:12, Loss:0.0087\n",
            "Epoch:13, Loss:0.0086\n",
            "Epoch:14, Loss:0.0085\n",
            "Epoch:15, Loss:0.0084\n",
            "Epoch:16, Loss:0.0085\n",
            "Epoch:17, Loss:0.0084\n",
            "Epoch:18, Loss:0.0085\n",
            "Epoch:19, Loss:0.0084\n",
            "Epoch:20, Loss:0.0084\n",
            "Epoch:21, Loss:0.0085\n",
            "Epoch:22, Loss:0.0085\n",
            "Epoch:23, Loss:0.0084\n",
            "Epoch:24, Loss:0.0085\n",
            "Epoch:25, Loss:0.0084\n",
            "Epoch:26, Loss:0.0084\n",
            "Epoch:27, Loss:0.0084\n",
            "Epoch:28, Loss:0.0084\n",
            "Epoch:29, Loss:0.0084\n",
            "Epoch:30, Loss:0.0084\n",
            "Epoch:31, Loss:0.0084\n",
            "Epoch:32, Loss:0.0084\n",
            "Epoch:33, Loss:0.0084\n",
            "Epoch:34, Loss:0.0084\n",
            "Epoch:35, Loss:0.0084\n",
            "Epoch:36, Loss:0.0084\n",
            "Epoch:37, Loss:0.0084\n",
            "Epoch:38, Loss:0.0084\n",
            "Epoch:39, Loss:0.0084\n",
            "Epoch:40, Loss:0.0084\n",
            "Epoch:41, Loss:0.0084\n",
            "Epoch:42, Loss:0.0084\n",
            "Epoch:43, Loss:0.0084\n",
            "Epoch:44, Loss:0.0084\n",
            "Epoch:45, Loss:0.0084\n",
            "Epoch:46, Loss:0.0084\n",
            "Epoch:47, Loss:0.0084\n",
            "Epoch:48, Loss:0.0084\n",
            "Epoch:49, Loss:0.0084\n",
            "Epoch:50, Loss:0.0084\n",
            "Epoch:51, Loss:0.0084\n",
            "Epoch:52, Loss:0.0084\n",
            "Epoch:53, Loss:0.0084\n",
            "Epoch:54, Loss:0.0084\n",
            "Epoch:55, Loss:0.0084\n",
            "Epoch:56, Loss:0.0084\n",
            "Epoch:57, Loss:0.0084\n",
            "Epoch:58, Loss:0.0084\n",
            "Epoch:59, Loss:0.0084\n",
            "Epoch:60, Loss:0.0084\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_nZ6XtLjjMn"
      },
      "source": [
        "## Model Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGp1T_uujjMo"
      },
      "source": [
        "Since our model is 'tested' with people listening to it, we need to just generate some samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgxPwKl9jjMr",
        "outputId": "84a3ac3c-14a9-42b2-a904-2ee6475ff3f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_data = data[:200]\n",
        "test_onehot_data = np.zeros([len(test_data),20,16])\n",
        "\n",
        "for i, sample in enumerate(test_data):\n",
        "    denorm = NumpyDenormalize(sample)\n",
        "    oneHot = NumpyOneHot(denorm)\n",
        "    test_onehot_data[i] = NumpyNormalize(oneHot, oneHot=True)\n",
        "\n",
        "test_data = torch.tensor(test_onehot_data).float()\n",
        "test_loader = torch.utils.data.DataLoader(test_data, \n",
        "                                           batch_size=1, \n",
        "                                           shuffle=True)\n",
        "\n",
        "song_length = 50\n",
        "new_song = np.zeros([1, 4])\n",
        "\n",
        "for sample in test_loader:\n",
        "    x = sample.detach().numpy() # (Batch_size,sequence,notes)\n",
        "    break\n",
        "\n",
        "for i, sample in enumerate(test_loader):\n",
        "    input = sample[:,:-1,:]\n",
        "    # Get note from classification model\n",
        "    new_note = model_classify(input)[0][-1].detach().numpy()\n",
        "    # Get other features (octave, velocity, time, sustain) from regression model\n",
        "    new_other = model_regr(input)[0][-1].detach().numpy()\n",
        "    # Get note value\n",
        "    note = np.argmax(new_note[:12], axis=-1)\n",
        "    new_other[:13] = (note*11*new_other[:13])/127\n",
        "    new_sample = new_other[12:]\n",
        "    new_sample = np.expand_dims(new_sample, axis=0)\n",
        "    if i == 0:\n",
        "        new_song = new_sample\n",
        "    else:\n",
        "        new_song = np.append(new_song, new_sample, axis=0)\n",
        "\n",
        "# new_excerpt = new_excerpt.type(torch.int64)\n",
        "print('new excerpt: (Watch for the same notes appearing...)',new_song)\n",
        "print('new_song.shape: ',new_song.shape)\n",
        "\n",
        "mid = Numpy2Midi(new_song, \"Autoencoder\")"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "new excerpt: (Watch for the same notes appearing...) [[0.3834609  0.45660052 0.0028351  0.00593412]\n",
            " [0.3821163  0.45710558 0.00278709 0.00582607]\n",
            " [0.3831455  0.45906025 0.0028632  0.00600822]\n",
            " [0.382161   0.45783398 0.00281245 0.00588372]\n",
            " [0.38231754 0.45766258 0.002908   0.00605456]\n",
            " [0.38201055 0.4579039  0.0028113  0.00591658]\n",
            " [0.38352874 0.4581072  0.00288846 0.00600024]\n",
            " [0.3815706  0.45730528 0.00276807 0.00578681]\n",
            " [0.38401175 0.45633325 0.00282622 0.00591725]\n",
            " [0.3833556  0.45674938 0.00286194 0.00598949]\n",
            " [0.38240764 0.45832255 0.00285517 0.00596364]\n",
            " [0.3817254  0.45709607 0.00282618 0.00597987]\n",
            " [0.38157952 0.4587788  0.00283522 0.00593847]\n",
            " [0.38183147 0.45716038 0.00282473 0.00586217]\n",
            " [0.38145664 0.4573909  0.00278628 0.00585354]\n",
            " [0.38213664 0.45871624 0.00279928 0.00589242]\n",
            " [0.3826056  0.4582725  0.00284061 0.00590227]\n",
            " [0.3829809  0.45654604 0.00288046 0.00600822]\n",
            " [0.38162538 0.45781347 0.00282432 0.00587628]\n",
            " [0.38137183 0.45971918 0.00285437 0.00593514]\n",
            " [0.38202378 0.4580977  0.0028538  0.00596069]\n",
            " [0.381862   0.4581002  0.00281322 0.00585566]\n",
            " [0.38179117 0.4577309  0.00282463 0.00586188]\n",
            " [0.38361105 0.4583595  0.00280015 0.00588716]\n",
            " [0.38033637 0.45980275 0.00283792 0.00589834]\n",
            " [0.3833039  0.4572554  0.00285089 0.00597591]\n",
            " [0.38139096 0.45837313 0.0028939  0.00601737]\n",
            " [0.38117945 0.45895466 0.0028308  0.00595608]\n",
            " [0.38232812 0.45829862 0.00279833 0.00590001]\n",
            " [0.3814987  0.45770806 0.00282416 0.00589239]\n",
            " [0.38272262 0.45716134 0.00277688 0.00581935]\n",
            " [0.38261726 0.45859405 0.00286597 0.00597106]\n",
            " [0.3808451  0.45946205 0.00285202 0.00594808]\n",
            " [0.3817749  0.45759252 0.00279637 0.00587697]\n",
            " [0.3813677  0.45775563 0.00278911 0.00581891]\n",
            " [0.38157952 0.4584446  0.00281736 0.00589268]\n",
            " [0.382754   0.45777616 0.0027757  0.00586401]\n",
            " [0.38277894 0.45752364 0.0027979  0.00588298]\n",
            " [0.38124824 0.4586374  0.00282044 0.00590391]\n",
            " [0.38217607 0.4570951  0.00291179 0.00608041]\n",
            " [0.38247737 0.45871377 0.00295512 0.00617121]\n",
            " [0.38189742 0.45676854 0.00278436 0.00585195]\n",
            " [0.38170156 0.45986307 0.00281012 0.00592683]\n",
            " [0.38301843 0.4579575  0.00279144 0.00583806]\n",
            " [0.3810989  0.4580021  0.00277261 0.00581526]\n",
            " [0.38112423 0.45900562 0.00285753 0.00594427]\n",
            " [0.38286772 0.45783538 0.00281327 0.00594777]\n",
            " [0.38247043 0.45783836 0.0028114  0.00590727]\n",
            " [0.38087702 0.45746973 0.00288642 0.00594544]\n",
            " [0.38261366 0.4556921  0.00278905 0.00585846]\n",
            " [0.3810832  0.45834458 0.0028792  0.00600774]\n",
            " [0.38257098 0.4583261  0.00283591 0.00592359]\n",
            " [0.38432667 0.45720634 0.00290857 0.00604151]\n",
            " [0.382494   0.4583263  0.00279924 0.00585162]\n",
            " [0.38218692 0.4558694  0.00282279 0.0059127 ]\n",
            " [0.38179633 0.45783368 0.00276052 0.00585417]\n",
            " [0.38237113 0.45715562 0.00282943 0.00591862]\n",
            " [0.3826288  0.45686838 0.00276876 0.00580028]\n",
            " [0.38255784 0.45863438 0.00278025 0.00584986]\n",
            " [0.38108173 0.45762476 0.00276972 0.00579707]\n",
            " [0.38141906 0.45745417 0.00283616 0.00592531]\n",
            " [0.3828956  0.45758379 0.00286644 0.00602919]\n",
            " [0.3811828  0.45845395 0.00284815 0.00589207]\n",
            " [0.38121083 0.45963702 0.00286297 0.00598538]\n",
            " [0.3814741  0.45974207 0.00286252 0.00595635]\n",
            " [0.38262954 0.45708537 0.0027981  0.00583471]\n",
            " [0.38384047 0.4569427  0.0028875  0.006017  ]\n",
            " [0.3830432  0.45727175 0.00282383 0.00592705]\n",
            " [0.38249755 0.45790964 0.00284566 0.00594023]\n",
            " [0.38177222 0.45874986 0.00281203 0.00588193]\n",
            " [0.383376   0.4565403  0.00277715 0.00587873]\n",
            " [0.381927   0.4571176  0.00279313 0.00586054]\n",
            " [0.38178727 0.45792565 0.00280568 0.00582723]\n",
            " [0.3820627  0.4580663  0.00282362 0.0058861 ]\n",
            " [0.38264194 0.45679688 0.00286062 0.00599479]\n",
            " [0.3821619  0.45691043 0.00285419 0.00594951]\n",
            " [0.38331798 0.45684212 0.00280935 0.00588772]\n",
            " [0.38151953 0.45853642 0.0028053  0.0058617 ]\n",
            " [0.38350502 0.4574411  0.00285774 0.00597909]\n",
            " [0.38176727 0.45895863 0.00283909 0.00594461]\n",
            " [0.38215014 0.4581755  0.00286592 0.00596111]\n",
            " [0.3830806  0.45721203 0.00277793 0.00581723]\n",
            " [0.38186973 0.4569777  0.00284    0.00597091]\n",
            " [0.38104132 0.4584627  0.00283075 0.00592426]\n",
            " [0.38286448 0.4562189  0.00275274 0.00580063]\n",
            " [0.3811843  0.4572783  0.00283648 0.0059268 ]\n",
            " [0.38246268 0.4563673  0.00278178 0.00582293]\n",
            " [0.3812825  0.4569884  0.0028164  0.00585571]\n",
            " [0.3818432  0.45681486 0.00285153 0.00594428]\n",
            " [0.3827559  0.45675036 0.0027848  0.00586773]\n",
            " [0.3819863  0.45796245 0.00284359 0.00598363]\n",
            " [0.3822771  0.45740658 0.0027764  0.00583901]\n",
            " [0.38213062 0.4586523  0.00282264 0.00588965]\n",
            " [0.38249052 0.45835912 0.00283585 0.00599444]\n",
            " [0.38290536 0.45782822 0.00286294 0.00595162]\n",
            " [0.38196498 0.45865613 0.00284465 0.00597067]\n",
            " [0.38148728 0.45829722 0.00280282 0.00583219]\n",
            " [0.38256904 0.45764413 0.00282371 0.00590592]\n",
            " [0.38296047 0.45729846 0.00283101 0.00594486]\n",
            " [0.38312557 0.45864093 0.00280002 0.00588385]\n",
            " [0.38143805 0.45741922 0.00280183 0.00589545]\n",
            " [0.3801794  0.4602311  0.00285473 0.00591065]\n",
            " [0.38310423 0.45778966 0.00282511 0.00589862]\n",
            " [0.38173005 0.45785496 0.00284192 0.00594208]\n",
            " [0.38345602 0.4574407  0.00279981 0.00586219]\n",
            " [0.38137993 0.4582351  0.00289722 0.00598041]\n",
            " [0.38262767 0.4582148  0.0028035  0.0058846 ]\n",
            " [0.38295436 0.45723215 0.00276176 0.00584211]\n",
            " [0.38414878 0.4569428  0.00281353 0.00590049]\n",
            " [0.38271415 0.45778024 0.00282568 0.00595223]\n",
            " [0.38164824 0.45792535 0.0028247  0.00591793]\n",
            " [0.38249537 0.45823702 0.00278924 0.00586716]\n",
            " [0.3813824  0.4586063  0.00279442 0.0058423 ]\n",
            " [0.38228378 0.45687664 0.00276024 0.00582265]\n",
            " [0.38216594 0.45790696 0.00281686 0.00587642]\n",
            " [0.38165325 0.45890224 0.00275568 0.00576035]\n",
            " [0.38270006 0.45751226 0.00280988 0.00588572]\n",
            " [0.38342628 0.45779905 0.00289333 0.00599684]\n",
            " [0.38250524 0.4566198  0.00278898 0.00587471]\n",
            " [0.38273218 0.4572179  0.00280035 0.0058721 ]\n",
            " [0.38345888 0.45773223 0.00283777 0.00594714]\n",
            " [0.38136277 0.45872054 0.00278076 0.0058471 ]\n",
            " [0.38171786 0.45812753 0.0028662  0.00597192]\n",
            " [0.38193688 0.45947462 0.00281086 0.00586655]\n",
            " [0.3820504  0.45791143 0.00279296 0.00584429]\n",
            " [0.38125485 0.45814723 0.00279065 0.00583427]\n",
            " [0.3816131  0.45802552 0.00286271 0.00600442]\n",
            " [0.38306573 0.4581167  0.00282493 0.00585006]\n",
            " [0.3815262  0.45757973 0.00287625 0.00600969]\n",
            " [0.38193247 0.45740458 0.00285611 0.00597005]\n",
            " [0.38127065 0.45649934 0.00276759 0.00579634]\n",
            " [0.3819172  0.4578854  0.00283008 0.0058997 ]\n",
            " [0.38223475 0.4570312  0.00287803 0.00598824]\n",
            " [0.381069   0.45943728 0.0028501  0.00592379]\n",
            " [0.38269684 0.45768338 0.00279352 0.00587818]\n",
            " [0.38132045 0.45925033 0.00281076 0.0059014 ]\n",
            " [0.38391533 0.45603472 0.00282071 0.00595645]\n",
            " [0.38158846 0.45909145 0.00285938 0.00595335]\n",
            " [0.3817175  0.45674285 0.0028871  0.00599814]\n",
            " [0.38267902 0.45772615 0.00280112 0.00585955]\n",
            " [0.38117734 0.45910206 0.00282902 0.00590287]\n",
            " [0.38195547 0.45771366 0.0027883  0.00585924]\n",
            " [0.38265616 0.45715043 0.00287777 0.00601753]\n",
            " [0.38276672 0.45867133 0.00285126 0.00596304]\n",
            " [0.38242298 0.45737475 0.00279656 0.00589422]\n",
            " [0.38268247 0.45738724 0.00284293 0.00597965]\n",
            " [0.38199192 0.45818016 0.00277503 0.00583953]\n",
            " [0.38464808 0.45378432 0.00288846 0.00605296]\n",
            " [0.38412726 0.4566722  0.00283294 0.00596307]\n",
            " [0.3837056  0.45717296 0.00282026 0.00592087]\n",
            " [0.3822274  0.45796224 0.00282849 0.00589162]\n",
            " [0.383367   0.45700425 0.00279596 0.00586273]\n",
            " [0.3842526  0.45633823 0.00278676 0.0059022 ]\n",
            " [0.38324067 0.45708084 0.00285462 0.00596401]\n",
            " [0.38057595 0.46034938 0.00281022 0.00587053]\n",
            " [0.38172433 0.45701012 0.00280905 0.00587809]\n",
            " [0.38288948 0.45723155 0.00280493 0.00593292]\n",
            " [0.3811775  0.45874563 0.00282108 0.00587951]\n",
            " [0.38123056 0.45682818 0.0028175  0.00588555]\n",
            " [0.38228735 0.45752934 0.00285068 0.00593551]\n",
            " [0.3817384  0.45865294 0.00284269 0.00590705]\n",
            " [0.38356513 0.45540974 0.00279467 0.00586159]\n",
            " [0.3822927  0.45928234 0.00282632 0.00590755]\n",
            " [0.38276973 0.4569122  0.00281449 0.00592549]\n",
            " [0.38117284 0.4592547  0.00282323 0.0058721 ]\n",
            " [0.3824083  0.45549792 0.00281343 0.00585467]\n",
            " [0.3811387  0.4584719  0.0028227  0.00597984]\n",
            " [0.38317764 0.45719802 0.00278476 0.00586904]\n",
            " [0.38209602 0.45718047 0.00282329 0.00588233]\n",
            " [0.38213426 0.45666528 0.00278807 0.00583899]\n",
            " [0.38070646 0.46076125 0.00284338 0.00593965]\n",
            " [0.38204643 0.46016014 0.00287166 0.00598552]\n",
            " [0.38239107 0.4566669  0.00282617 0.00593079]\n",
            " [0.3819265  0.45791665 0.00278975 0.00585231]\n",
            " [0.3831738  0.4554798  0.00275539 0.00583976]\n",
            " [0.38245368 0.45893648 0.00283085 0.00593764]\n",
            " [0.38359633 0.45818827 0.00292243 0.00603439]\n",
            " [0.38257593 0.45791245 0.00285411 0.00597923]\n",
            " [0.3832156  0.45733866 0.00278948 0.00585017]\n",
            " [0.38251215 0.4577715  0.00285518 0.00592754]\n",
            " [0.3816207  0.45839038 0.0027587  0.00581739]\n",
            " [0.3835764  0.4577761  0.00278885 0.0059028 ]\n",
            " [0.38266122 0.4580775  0.00283457 0.0059042 ]\n",
            " [0.3809357  0.45758373 0.00282585 0.00590878]\n",
            " [0.3811072  0.45753622 0.00279112 0.0058657 ]\n",
            " [0.38125145 0.45848158 0.00284289 0.00594261]\n",
            " [0.38071963 0.46047008 0.00287855 0.00597915]\n",
            " [0.38140777 0.4569517  0.00281812 0.0058832 ]\n",
            " [0.38147917 0.45793074 0.00281125 0.00590564]\n",
            " [0.38128507 0.45805222 0.00286157 0.00595099]\n",
            " [0.38107574 0.45891008 0.00284433 0.00588098]\n",
            " [0.3827653  0.45683932 0.00281734 0.00592666]\n",
            " [0.38162318 0.45626554 0.00287232 0.00602006]\n",
            " [0.38297907 0.4568859  0.00283251 0.0059326 ]\n",
            " [0.38307908 0.456958   0.00278174 0.00587507]\n",
            " [0.38067728 0.45853767 0.00282321 0.00585457]\n",
            " [0.38241357 0.45758584 0.00279744 0.00590105]\n",
            " [0.3819213  0.4594023  0.00294144 0.00609179]\n",
            " [0.38226977 0.45776162 0.00278787 0.005838  ]\n",
            " [0.3823923  0.45651534 0.00281414 0.00590941]]\n",
            "new_song.shape:  (200, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}