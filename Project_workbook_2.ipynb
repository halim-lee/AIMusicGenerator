{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project File - APS360 Team 25\n",
    "Divided into the following section: \n",
    "# \n",
    "1) Library imports\n",
    "2) Data imports\n",
    "3) Model architecture definition\n",
    "4) Training function definition\n",
    "5) Model training\n",
    "6) Model testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library imports \n",
    "(Place all library imports here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KP - I just added the main ones from the labs.\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "#import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import time # Tracking model training time.\n",
    "\n",
    "#for Data importing\n",
    "import mido\n",
    "from mido import MidiFile, Message, MidiTrack, MetaMessage\n",
    "import os\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data imports\n",
    "#### MIDI reading functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CountTracks(directory):          #Count files and tracks in folder\n",
    "    trackCount = 0\n",
    "    fileCount = 0\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(\".midi\"):\n",
    "            fileCount += 1\n",
    "            midiDir = MidiFile(directory+\"/\"+file)\n",
    "            for track in midiDir.tracks:\n",
    "                trackCount += 1\n",
    "    print(fileCount+\" files\")\n",
    "    print(trackCount+\" tracks\")\n",
    "\n",
    "    \n",
    "def PrintMessages(mid):                # print midi messages\n",
    "    for i, track in enumerate(mid.tracks):\n",
    "        print('Track {}: {}'.format(i, track.name))\n",
    "        for msg in track:\n",
    "            print(msg)\n",
    "\n",
    "            \n",
    "def PrintSomeMessages(mid):             #print first 200 midi messages\n",
    "    track = mid.tracks[1]\n",
    "    for i,msg in enumerate(track):\n",
    "        if i < 200:\n",
    "            print(msg)\n",
    "            \n",
    "def PrintMetaMessages(mid):             #print fmeta messages\n",
    "    track = mid.tracks[0]\n",
    "    for i,msg in enumerate(track):\n",
    "        print(msg)\n",
    "\n",
    "def cleanupMessages(mid):              #removes non-note messages by force\n",
    "    track = mid.tracks[1]\n",
    "    track2 = []\n",
    "    for msg in track:\n",
    "        if msg.type == \"note_on\":\n",
    "            track2.append(msg)\n",
    "    mid.tracks[1] = track2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MIDI to Numpy code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Midi2NumpyNoSustain(mid, track0=1):                                #converts to numpy array removing non-note messages\n",
    "    track = mid.tracks[track0]                           #0th track only contains meta-messages, all notes on 1st track\n",
    "    notes = np.empty([0,4])\n",
    "    time = 0\n",
    "    for msg in track:\n",
    "        if msg.type == \"note_on\":                   # only count \"note\" messages - other inputs i.e. foot pedals are ignored\n",
    "            notes = np.append(notes,np.array([[msg.note, msg.velocity, msg.time + time, 0]]),axis=0)         # (note, velocity, time, sustain)\n",
    "            time = 0\n",
    "        elif msg.type == \"note_off\":\n",
    "            notes = np.append(notes,np.array([[msg.note, 0, msg.time + time, 0]]),axis=0)         # (note, velocity, time, sustain)\n",
    "            time = 0        \n",
    "        else:\n",
    "            time += msg.time                        #adjust time when removing other messages\n",
    "    return notes\n",
    "\n",
    "\n",
    "def NumpyGetSustain(note):\n",
    "    notes = np.copy(note)\n",
    "    for i, msg in enumerate(notes):\n",
    "        if msg[1] > 0:                            # if velocity is not 0\n",
    "            j = 1\n",
    "            sustain = 0\n",
    "            while msg[0] != notes[i+j][0]:        # while note values are different\n",
    "                sustain += notes[i+j][2]\n",
    "                j += 1                            #search for next message with same note i.e. message telling that note was released\n",
    "            notes[i,3] = sustain + notes[i+j][2]\n",
    "    time = 0\n",
    "    for i, msg in enumerate(notes):\n",
    "        if msg[1] > 0:\n",
    "            notes[i,2] += time\n",
    "            time = 0\n",
    "        else:\n",
    "            time += msg[2]                        #adjust time\n",
    "    notes = notes[notes[:,1] > 0]                 #filter for notes with positive velocities (note presses)\n",
    "    return notes\n",
    "\n",
    "def NumpyNormalize(note, oneHot=False, full=False):                         #normalize all values to 0-1\n",
    "    notes = np.copy(note)\n",
    "    \n",
    "    if oneHot:\n",
    "        if full:\n",
    "            notes[:,88] /= 128\n",
    "            notes[:,89] /= 40000\n",
    "            notes[:,90] /= 40000\n",
    "        else:\n",
    "            notes[:,12] /= 11\n",
    "            notes[:,13] /= 128\n",
    "            notes[:,14] /= 40000\n",
    "            notes[:,15] /= 40000\n",
    "    else:\n",
    "        notes[:,0] /= 128\n",
    "        notes[:,1] /= 128\n",
    "        notes[:,2] /= 40000\n",
    "        notes[:,3] /= 40000       \n",
    "    return notes\n",
    "\n",
    "def NumpyOneHot(note):\n",
    "    notes = np.copy(note)\n",
    "    oneHot = np.zeros([len(notes),16])\n",
    "    oneHot[:, 13:] = notes[:, 1:]\n",
    "    names = notes[:,0]\n",
    "    namesOct = names%12\n",
    "    oneHot[:,12] = (names-(namesOct))/12\n",
    "    \n",
    "    for i, name in enumerate(namesOct):\n",
    "        oneHot[i,name.astype(int)] = 1\n",
    "    \n",
    "    return oneHot\n",
    "\n",
    "def NumpyNotesOneHot(note):\n",
    "    notes = np.copy(note)\n",
    "    \n",
    "    oneHot = np.zeros([len(notes),131])\n",
    "    oneHot[:, 128:] = notes[:, 1:]\n",
    "    names = notes[:,0]\n",
    "    #namesOct = names%12\n",
    "    #oneHot[:,12] = (names-(namesOct))/12\n",
    "    \n",
    "    for i, name in enumerate(names):\n",
    "        oneHot[i,name.astype(int)] = 1\n",
    "    \n",
    "    return oneHot\n",
    "\n",
    "def Midi2Numpy(path, oneHot=False, track0=1): # full midi to numpy conversion\n",
    "    mid = MidiFile(path)\n",
    "    notes = Midi2NumpyNoSustain(mid, track0=track0)\n",
    "    cleanNotes = NumpyGetSustain(notes)\n",
    "    \n",
    "    if oneHot:\n",
    "        cleanNotes = NumpyOneHot(cleanNotes)\n",
    "    \n",
    "    normNotes = NumpyNormalize(cleanNotes, oneHot=oneHot)\n",
    "    return normNotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numpy to MIDI code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NumpyDenormalize(note): # interpret all values from 0-1 to normal values\n",
    "    notes = np.copy(note)    \n",
    "    if notes.shape[1] == 16: # if encode as one-hot\n",
    "        notes[:,12] *= 11 # octave\n",
    "        notes[:,13] *= 128 # vel\n",
    "        notes[:,14] *= 40000 # time\n",
    "        notes[:,15] *= 40000 # sustain\n",
    "        \n",
    "        notes = NumpyEncode(notes) #encode back as original 4-variable format\n",
    "        \n",
    "    elif notes.shape[1] == 91: # if encoded as one-hot w/o octave\n",
    "        notes[:,88] *= 128\n",
    "        notes[:,89] *= 40000\n",
    "        notes[:,90] *= 40000\n",
    "        \n",
    "        #print(notes)\n",
    "        \n",
    "        notes = NumpyEncodeNotes(notes)\n",
    "        \n",
    "    else:\n",
    "        notes[:,0] *= 128\n",
    "        notes[:,1] *= 128\n",
    "        notes[:,2] *= 40000\n",
    "        notes[:,3] *= 40000       \n",
    "    return notes.astype(int)\n",
    "\n",
    "def NumpyEncode(note): # convert back from one-hot encoding\n",
    "    notes = np.copy(note)    \n",
    "    encoded = np.zeros([len(notes),4]) # create array   \n",
    "    encoded[:, 1:] = notes[:, 13:] # set vel/time/sustain\n",
    "    encoded[:, 0] = notes[:,12]*12 # add octave value\n",
    "    \n",
    "    for i in range(len(notes)):\n",
    "        encoded[i,0] += np.argmax(notes[i,:12])\n",
    "    \n",
    "    return encoded\n",
    "\n",
    "def NumpyEncodeNotes(note): # convert back from one-hot encoding\n",
    "    notes = np.copy(note)    \n",
    "    encoded = np.zeros([len(notes),4])\n",
    "    \n",
    "    encoded[:, 1:] = notes[:, 88:] # set vel/time/sustain\n",
    "    \n",
    "    for i in range(len(notes)):\n",
    "        encoded[i,0] += np.argmax(notes[i,:88])+21\n",
    "    \n",
    "    return encoded\n",
    "\n",
    "def NumpySequence(notes): # put all notes into a \"timeline\" i.e.: time values of [10, 20, 10, 30] become [10, 30, 40, 70]\n",
    "    sequenced = np.copy(notes)                      # this allows us to easily add vel=0 notes in any order since we can later sort them by time\n",
    "    for i, msg in enumerate(sequenced):\n",
    "        if i > 0:\n",
    "            sequenced[i,2] += sequenced[i-1,2]\n",
    "    return sequenced\n",
    "\n",
    "def NumpyAddOffNotes(sequenced): # add vel=0 notes from sustain into sequenced timeline\n",
    "    withOff = np.copy(sequenced)\n",
    "    for msg in sequenced:\n",
    "        offNote = np.array([[msg[0], 0, msg[2] + msg[3], 0]])\n",
    "        withOff = np.append(withOff, offNote, axis=0)\n",
    "    #withOff = np.sort(withOff,axis=0)\n",
    "    withOff = withOff[withOff[:,2].argsort()] # sort by time\n",
    "    return withOff\n",
    "\n",
    "def NumpyUnsequence(notes): # revert time value to \"time since last message\"\n",
    "    unsequenced = np.copy(notes)\n",
    "    for i, msg in reversed(list(enumerate(unsequenced))):\n",
    "        unsequenced[i,3] = 0\n",
    "        if i > 0:\n",
    "            unsequenced[i,2] -= unsequenced[i-1,2]\n",
    "    return unsequenced\n",
    "\n",
    "def Numpy2MidiDirect(array):    #make MIDI object from numpy\n",
    "    #Start with initializing a new Mido Track:\n",
    "    mid = MidiFile()\n",
    "    track0 = MidiTrack()\n",
    "    track1 = MidiTrack()\n",
    "    \n",
    "    track0.append(MetaMessage('set_tempo', tempo=500000, time=0)) #MetaMessages not necessary but are present in used files\n",
    "    track0.append(MetaMessage('time_signature', numerator=4, denominator=4, clocks_per_click=24, notated_32nd_notes_per_beat=8, time=0))\n",
    "    track0.append(MetaMessage('end_of_track', time=1))\n",
    "    \n",
    "    track1.append(Message('program_change', channel=0, program=0, time=0))\n",
    "    \n",
    "    for i,note in enumerate(array):         # Get the index and the note. Array must be int array\n",
    "        j = 1\n",
    "        track1.append(Message('note_on',note = array[i,0], velocity = array[i,1],time = array[i,2])) # Add the note to the track.\n",
    "\n",
    "    mid.tracks.append(track0)\n",
    "    mid.tracks.append(track1)\n",
    "    return mid\n",
    "\n",
    "def Numpy2Midi(notes, name): # full numpy to midi conversion, saving result to [name].midi\n",
    "    denorm = NumpyDenormalize(notes)\n",
    "    seq = NumpySequence(denorm)\n",
    "    off = NumpyAddOffNotes(seq)\n",
    "    unseq = NumpyUnsequence(off)\n",
    "    mid = Numpy2MidiDirect(unseq)\n",
    "    mid.save(name + \".midi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitTrack(midiFileName, inputDir, outputDir):\n",
    "    mid = MidiFile(inputDir+midiFileName+\".midi\")\n",
    "    for t, track in enumerate(mid.tracks):\n",
    "        program, channel = findInstrument(track)        \n",
    "        if len(track) < 200 or program == -1:\n",
    "            continue\n",
    "        trackMidi = copy.copy(mid)\n",
    "        indices = [t]\n",
    "        trackMidi.tracks = [trackMidi.tracks[x] for x in indices]\n",
    "        #trackMidi.tracks.append(track)\n",
    "        trackMidi.save(outputDir + midiFileName + \"_prog{:0>3d}_chan{:0>2d}.midi\".format(program,channel))\n",
    "\n",
    "def splitAllTracks(inputDir, outputDir, first=0): # very bad code -  doesnt remove the .midi in the middle lol\n",
    "    for i,f in enumerate(os.listdir(inputDir)):\n",
    "        if i >= first:\n",
    "            if len(f) <7:\n",
    "                continue\n",
    "            splitTrack(f[:7],inputDir,outputDir)\n",
    "\n",
    "            if i % 1 == 0:\n",
    "                print(f)\n",
    "        \n",
    "def findInstrument(track):\n",
    "    count = 0\n",
    "    infoMsg = 0\n",
    "    \n",
    "    for msg in track:\n",
    "        if msg.type == \"program_change\":\n",
    "            count += 1\n",
    "            infoMsg = msg\n",
    "    \n",
    "    if count >= 1:\n",
    "        if infoMsg.channel == 9 or count == 1:\n",
    "            return infoMsg.program, infoMsg.channel\n",
    "        else: \n",
    "            return -1, -1\n",
    "    else:\n",
    "        return -1, -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#splitAllTracks(\"data/jazz/\",\"data/jazz/tracks/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generatng tensor dataset from CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Numpy2Dataset(notes, tgt, num=50,skip=100, train=False): # make list of sumpy arrays\n",
    "    #mult = [0.8, 3/2, 3, 2, 10.2, 10, 25, 5.5, -1]\n",
    "    mult = [0.8, 3/2, 3, 2, 10.2, 10, 40, 5.5, -1]\n",
    "    \n",
    "    samples = []\n",
    "    targets = []\n",
    "    \n",
    "    if mult[tgt] == -1:\n",
    "        return [], []\n",
    "    \n",
    "    if train:\n",
    "        skip = int(skip/mult[tgt])\n",
    "    \n",
    "    i = 0\n",
    "    while i+num <= len(notes):\n",
    "        samples.append(notes[i:i+num])\n",
    "        targets.append(tgt)\n",
    "        i += skip\n",
    "    return samples, targets\n",
    "\n",
    "def SampleAllNumpy(dataPath, train=False): # generate samples from all saved CSVs\n",
    "    allSamples = []\n",
    "    allTargets = []\n",
    "\n",
    "    for i,f in enumerate(os.listdir(dataPath)):\n",
    "        notes = np.genfromtxt(dataPath+f, delimiter=',')\n",
    "        tgt = GetGroup(f)\n",
    "                             \n",
    "        samples, targets = Numpy2Dataset(notes, tgt, train=train)\n",
    "        allSamples += samples\n",
    "        allTargets += targets\n",
    "        if i % 100 == 0:\n",
    "            print(i)\n",
    "            \n",
    "    random.seed(0)\n",
    "    random.shuffle(allSamples)\n",
    "    random.seed(0)\n",
    "    random.shuffle(allTargets) # shuffle samples and targets in the exact same way   \n",
    "    \n",
    "    #print(CountTargets(allTargets))\n",
    "    \n",
    "    return allSamples, allTargets\n",
    "\n",
    "def CountTargets(targets, balance=10000):\n",
    "    count = [0,0,0,0,0,0,0,0,0,0]\n",
    "    \n",
    "    for tgt in targets:\n",
    "        count[tgt] += 1\n",
    "        \n",
    "    bal = np.array([10000,10000,10000,10000,10000,10000,10000,10000,10000,10000])\n",
    "\n",
    "    return (np.array(count)-bal)\n",
    "\n",
    "def SaveSamplesTensor(samples, targets, outputPath, name=\"Notes_Dataset\"): # save tensor\n",
    "    tens = torch.Tensor(samples)\n",
    "    targ = torch.Tensor(targets)\n",
    "    dataset = TensorDataset(tens,targ)\n",
    "    torch.save(dataset, outputPath+name+\".pt\")\n",
    "    return tens   \n",
    "\n",
    "def SaveAllSamples(dataPath, outputPath, name=\"Notes_Dataset\", train=False): # save dataset tensor\n",
    "    samples, targets = SampleAllNumpy(dataPath, train=train)\n",
    "    SaveSamplesTensor(samples, targets, outputPath, name)\n",
    "    \n",
    "def SplitSamples(dataset, ranges):\n",
    "    torch.maual_seed(0)\n",
    "    trainData, valData, testData = random_split(oneHotDataset, splitRange)\n",
    "    return trainData, valData, testData \n",
    "\n",
    "def CountLabels(ds):\n",
    "    count = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "    \n",
    "    for img, label in iter(ds):\n",
    "        lab = label.int().item()\n",
    "        count[lab] += 1\n",
    "        \n",
    "    #print(count)\n",
    "    return(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProgramGroup(program, channel):\n",
    "    if channel == 9:\n",
    "        return 0 # drums\n",
    "    if program < 8:\n",
    "        return 1 # piano\n",
    "    if program < 16:\n",
    "        return 8 # other - not used\n",
    "    if program < 24:\n",
    "        return 1 # organ -> piano\n",
    "    if program < 32:\n",
    "        return 3 # guitar\n",
    "    if program < 40:\n",
    "        return 2 # bass\n",
    "    if program < 56:\n",
    "        return 7 # ensemble/string\n",
    "    if program < 64:\n",
    "        return 4 # brass \n",
    "    if program < 80:\n",
    "        return 5 # woodwinds\n",
    "    if program < 88:\n",
    "        return 6 # synth lead\n",
    "    else:\n",
    "        return 8 # other - not used\n",
    "    \n",
    "def GetProgram(name):\n",
    "    prog = name[12:15]\n",
    "    chan = name[20:22]\n",
    "    return int(prog), int(chan)\n",
    "\n",
    "def GetGroup(name):\n",
    "    prog, chan = GetProgram(name)\n",
    "    group = ProgramGroup(prog, chan)\n",
    "    return(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = torch.load(\"data/trainDataClass.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84592"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bulk data conversion code - COMMENT OUT IF NOT IN USE!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "#SaveAllSamples(\"data/jazz/tracks_numpy_onehot/train/\",\"data/\",\"trainDataClassOnehot\", train=True) #save all into tensor\n",
    "SaveAllSamples(\"data/jazz/tracks_numpy/val/\",\"data/\",\"valDataClass\", train=True) #save all into tensor\n",
    "#SaveAllSamples(\"data/jazz/tracks_numpy_onehot/test/\",\"data/\",\"testDataClassOnehot\") #save all into tensor\n",
    "\n",
    "# oneHotDataset = torch.load(\"data/onehot_data/onehot.pt\")\n",
    "\n",
    "# splitProp = np.array([0.9, 0.05 , 0.05]) # 90/5/5% split\n",
    "# splitRange = len(oneHotDataset)*splitProp\n",
    "# splitRange[0] += 1                           # so numbers add up\n",
    "# splitRange = splitRange.astype(int)\n",
    "\n",
    "# length = len(oneHotDataset)\n",
    "# a = 0.9*length\n",
    "# a = int(a)\n",
    "\n",
    "# b = 0.95*length\n",
    "# b = int(b)\n",
    "\n",
    "# tiny = oneHotDataset[:30]\n",
    "# train = oneHotDataset[:a]\n",
    "# val = oneHotDataset[a:b]\n",
    "# test = oneHotDataset[b:]\n",
    "\n",
    "# tinyData = TensorDataset(tiny[0].clone(), tiny[1].clone())\n",
    "# trainData = TensorDataset(train[0].clone(),train[1].clone())\n",
    "# valData = TensorDataset(val[0].clone(),val[1].clone())\n",
    "# testData = TensorDataset(test[0].clone(),test[1].clone())\n",
    "\n",
    "# torch.save(tinyData,\"data/onehot_data/tinyDataOneHot.pt\")\n",
    "# torch.save(trainData,\"data/onehot_data/trainDataOneHot.pt\")\n",
    "# torch.save(valData,\"data/onehot_data/valDataOneHot.pt\")\n",
    "# torch.save(testData,\"data/onehot_data/testDataOneHot.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainData = torch.load(\"data/trainDataClassOnehot.pt\")\n",
    "valData = torch.load(\"data/valDataClass.pt\")\n",
    "#testData = torch.load(\"data/testDataClassOnehot.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[511, 453, 594, 555, 603, 504, 583, 533, 0, 0, 0]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CountLabels(valData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: COMMENT OUT IF NOT IN USE TO AVOID ACCIDENTS!!!!!!!\n",
    "\n",
    "# Getting CSVs from MIDI data and processed data from CSVs\n",
    "# Processed MIDI does not contain program messages and so are a good measure of what output SHOULD look like in a perfect world\n",
    "\n",
    "# dataPath = \"data/jazz/tracks/\"\n",
    "# outputPath = \"data/jazz/tracks_numpy/\"\n",
    "# #processedPath = \"data/MIDI_files_processed/\"\n",
    "\n",
    "# for i,f in enumerate(os.listdir(dataPath)):\n",
    "#     if i > 2700:\n",
    "#         notes = Midi2Numpy(dataPath+f,track0=0)\n",
    "#         np.savetxt(outputPath + f[:22]+\".csv\",notes,delimiter=\",\")\n",
    "#     #Numpy2Midi(notes, processedPath + \"MIDI_{:04d}\".format(i))\n",
    "#     #break\n",
    "    \n",
    "#     if i % 200 == 0:\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: COMMENT OUT IF NOT IN USE TO AVOID ACCIDENTS!!!!!!!\n",
    "\n",
    "# Getting CSVs from MIDI data and processed data from CSVs\n",
    "# Processed MIDI does not contain program messages and so are a good measure of what output SHOULD look like in a perfect world\n",
    "\n",
    "dataPath = \"data/jazz/tracks/\"\n",
    "outputPath = \"data/jazz/tracks_numpy/\"\n",
    "#processedPath = \"data/MIDI_files_processed/\"\n",
    "\n",
    "for i,f in enumerate(os.listdir(dataPath)):\n",
    "    if i == 47:\n",
    "        print(f)\n",
    "        testMidi = MidiFile(dataPath+f)\n",
    "        #PrintMessages(testMidi)\n",
    "        print(GetGroup(f))\n",
    "    #Numpy2Midi(notes, processedPath + \"MIDI_{:04d}\".format(i))\n",
    "    #break\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = \"data/jazz/tracks_numpy_all/\"  # one-hot encoding on CSVs\n",
    "outputPath = \"data/jazz/tracks_numpy_onehot/\"\n",
    "\n",
    "for i,f in enumerate(os.listdir(dataPath)):\n",
    "    notes = np.genfromtxt(dataPath+f, delimiter=',')\n",
    "    notes = NumpyDenormalize(notes)\n",
    "    notes = NumpyNotesOneHot(notes)\n",
    "    notes = NumpyNormalize(notes, oneHot=True, full=True)\n",
    "    np.savetxt(outputPath + f,notes,delimiter=\",\")\n",
    "    if i % 100 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model Code\n",
    "#### getting available notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetAllNotesMajor(root):# Get all used notes in major scale of root=root\n",
    "    notes = []\n",
    "    intervals = [2,2,1,2,2,2,1]\n",
    "    \n",
    "    while root > 24: #bring down to lowest used octave\n",
    "        root -= 12\n",
    "    \n",
    "    n = root\n",
    "    notes.append(n)\n",
    "    while n < 84: #up to higherst used note\n",
    "        for i in intervals:\n",
    "            n += i\n",
    "            notes.append(n)   \n",
    "    return notes    \n",
    "\n",
    "\n",
    "def GetRangeMajor(notes, low, high): # Get all notes within range\n",
    "    lowIndex = notes.index(low)\n",
    "    highIndex = notes.index(high)\n",
    "    \n",
    "    return notes[lowIndex:highIndex+1]   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Piece Class\n",
    "##### represents whole output from all 4 voices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Piece: # Entire baseline model compostion - composed of 4 voices soprano, alto, tenor, bass (SATB)\n",
    "    def __init__(self, barNum=16, root=60):# 16 bars in C major\n",
    "        self.root = root # root note\n",
    "        self.allNotes = GetAllNotesMajor(self.root) # all notes on major scale\n",
    "        self.barNum = barNum # number of bars\n",
    "        \n",
    "        self.soprano = Voice(self.allNotes,60,84,speed=8) # SATB\n",
    "        self.alto = Voice(self.allNotes,48,72)\n",
    "        self.tenor = Voice(self.allNotes,36,60)\n",
    "        self.bass = Voice(self.allNotes,24,48)\n",
    "          \n",
    "        self.notes = np.empty([0,4]) #notes output\n",
    "        \n",
    "        self.pieceChords = [] # chords\n",
    "        \n",
    "        self.chords = np.array([ # common classical C major chords\n",
    "            [ 0,  4,  7,  0],# I\n",
    "            [ 2,  5,  9,  2],# ii\n",
    "            [ 4,  7, 11,  4],# iii\n",
    "            [ 5,  9, 0,  5],# IV\n",
    "            [ 7, 11, 2,  7],# V\n",
    "            [ 9, 0, 4,  9],# vi\n",
    "            [11, 2, 5, 11],# vii dim\n",
    "            [ 2,  5,  9, 0],# ii7\n",
    "            [ 5,  9, 0, 4],# IVmaj7\n",
    "            [ 7, 11, 2, 5],# V7\n",
    "            [11, 2, 5, 9]])# vii7 half-dim\n",
    "        \n",
    "    def GenerateSoprano(self): # Generate soprano line\n",
    "        self.soprano.GenerateLine(self.soprano.speed*self.barNum)\n",
    "        \n",
    "    def GenerateAlto(self): # Generate alto line from chords\n",
    "        self.alto.GenerateChordLine(self.pieceChords)\n",
    "        \n",
    "    def GenerateTenor(self): # see alto\n",
    "        self.tenor.GenerateChordLine(self.pieceChords)\n",
    "        \n",
    "    def GenerateBass(self): # see alto\n",
    "        self.bass.GenerateChordLine(self.pieceChords)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def ChooseChord(self, sopNote): # Choose a fitting chord for soprano note\n",
    "        while sopNote >= 12:\n",
    "            sopNote -= 12\n",
    "        \n",
    "        goodChords = np.empty([0,4])\n",
    "        \n",
    "        for chord in self.chords:\n",
    "            if (chord==sopNote).sum() > 0:\n",
    "                goodChords = np.append(goodChords,[chord],axis=0)\n",
    "        \n",
    "        chosenChord = goodChords[random.randint(0,len(goodChords)-1)]\n",
    "        chosenChord = np.sort(np.unique(chosenChord))\n",
    "        \n",
    "        i = 12\n",
    "        chordNotes = chosenChord\n",
    "        while i < 120:\n",
    "            chordNotes = np.append(chordNotes, chosenChord+i)\n",
    "            i += 12\n",
    "        \n",
    "        return(chordNotes)\n",
    "    \n",
    "    def GetChords(self): # select all chords in piece\n",
    "        for i, note in enumerate(self.soprano.notes):\n",
    "            if i % 2 == 0:\n",
    "                sopNote = note[0]\n",
    "                chord = self.ChooseChord(sopNote)\n",
    "                self.pieceChords.append(chord)\n",
    "                \n",
    "    def Normalize(self): # normalize all values to 0-1\n",
    "        for i, msg in enumerate(self.notes):\n",
    "            self.notes[i,0] = msg[0]/128\n",
    "            self.notes[i,1] = msg[1]/128\n",
    "            self.notes[i,2] = msg[2]/40000\n",
    "            self.notes[i,3] = msg[3]/40000\n",
    "                \n",
    "    def GenerateLines(self): # Generate all SATB lines and joins them - entire baseline model\n",
    "        self.GenerateSoprano()\n",
    "        self.GetChords()\n",
    "        self.GenerateAlto()\n",
    "        self.GenerateTenor()\n",
    "        self.GenerateBass()\n",
    "        self.joinLines()\n",
    "        self.OffsetTime(20)\n",
    "        self.Normalize()\n",
    "        \n",
    "        return self.notes\n",
    "        \n",
    "    def InsertLine(self, starting, inserted, startIndex, skipIndex): # join 2 lines\n",
    "        base = np.copy(starting)\n",
    "        ins = np.copy(inserted)\n",
    "        \n",
    "        for i,note in enumerate(ins):\n",
    "            base = np.insert(base, (i*skipIndex)+startIndex, [note], axis=0)\n",
    "            \n",
    "        return base\n",
    "        \n",
    "    def joinLines(self): # join all SATB lines\n",
    "        #self.notes = np.copy(self.soprano)\n",
    "        self.notes = self.InsertLine(self.soprano.notes, self.alto.notes, 1, 3)\n",
    "        self.notes = self.InsertLine(self.notes, self.tenor.notes, 2, 4)\n",
    "        self.notes = self.InsertLine(self.notes, self.bass.notes, 3, 5)\n",
    "        \n",
    "    def OffsetTime(self, maxChange): # adds random time offsets to make output sound more organic\n",
    "        for note in self.notes:\n",
    "            note[2] += random.randint(0,maxChange)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Voice class\n",
    "##### Represents individual voices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Voice: # individual voices\n",
    "    def __init__(self, allNotes, lowNote, highNote, jump=3, speed=4, time=4096, velocity=64):\n",
    "        self.range = GetRangeMajor(allNotes,lowNote,highNote) #available ntoes\n",
    "        self.jump = jump #maximum pitch interval between notes\n",
    "        self.speed = speed #note length i.e. 4 for quarter, 8 for eighth etc.\n",
    "        self.time = time #song speed\n",
    "        self.velocity = velocity #note volume\n",
    "        self.notes = np.empty([0,4]) #notes output\n",
    "        self.lowNote = lowNote # lowest note\n",
    "        self.highNote = highNote # highest note\n",
    "        self.allNotes = allNotes # all notes in scale\n",
    "            \n",
    "        self.duration = self.time / self.speed # time between notes\n",
    "        \n",
    "        \n",
    "    def RandomStartNote(self): # Generate Random first note (for soprano)\n",
    "        note = random.choice(self.range)\n",
    "        self.notes = np.append(self.notes,np.array([[note, self.velocity, 0, self.duration]]),axis=0)\n",
    "        \n",
    "        \n",
    "    def RandomJump(self): # Generate Random next note (for soprano)\n",
    "        lastNote = self.notes[len(self.notes)-1][0] # find last played note\n",
    "        lastIndex = self.range.index(lastNote)\n",
    "        \n",
    "        newIndex = -1\n",
    "        while newIndex < 0 or newIndex >= len(self.range): # stay in range\n",
    "            newIndex = lastIndex + random.randint(-self.jump,self.jump)\n",
    "            \n",
    "        newNote = self.range[newIndex]\n",
    "        self.notes = np.append(self.notes,np.array([[newNote, self.velocity, self.duration, self.duration]]),axis=0)\n",
    "        \n",
    "        \n",
    "    def GenerateLine(self, length): # Generate random line (for soprano)\n",
    "        self.RandomStartNote()\n",
    "        \n",
    "        for n in range(length-1):\n",
    "            self.RandomJump()\n",
    "            \n",
    "            \n",
    "    def clearNotes(self):\n",
    "        self.notes = np.empty([0,4])\n",
    "        \n",
    "    def GetChordNotes(self, chordNotes): # Get useful notes from all chord notes\n",
    "        chordNotes = chordNotes[chordNotes >= self.lowNote]\n",
    "        chordNotes = chordNotes[chordNotes <= self.highNote]\n",
    "        return chordNotes\n",
    "    \n",
    "    def ChooseStartChordNote(self, chordNotes): # Choose Random note in chord\n",
    "        note = random.choice(chordNotes)\n",
    "        self.notes = np.append(self.notes,np.array([[note, self.velocity, 0, self.duration]]),axis=0)\n",
    "        \n",
    "    def ChooseChordNote(self,chordNotes): # Choose suitable next note in chord\n",
    "        lastNote = self.notes[len(self.notes)-1][0] # find last played note\n",
    "        \n",
    "        chordNotes = chordNotes[chordNotes >= lastNote - (self.jump*2)]\n",
    "        chordNotes = chordNotes[chordNotes <= lastNote + (self.jump*2)]\n",
    "        newNote = random.choice(chordNotes)\n",
    "        \n",
    "        self.notes = np.append(self.notes,np.array([[newNote, self.velocity, 0, self.duration]]),axis=0)\n",
    "        \n",
    "    def GenerateChordLine(self, chords): # Generate A/T/B lines\n",
    "        \n",
    "        firstChord = self.GetChordNotes(chords[0])\n",
    "        self.ChooseStartChordNote(firstChord)\n",
    "        \n",
    "        for c in chords[1:]:\n",
    "            chord = self.GetChordNotes(c)\n",
    "            self.ChooseChordNote(chord)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the hyperparameters below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "class MusicGenerator(nn.Module):\n",
    "    def __init__(self, input_size=16, hidden_size=128):\n",
    "        super(MusicGenerator, self).__init__()\n",
    "        self.name = \"SergModel\"\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.rnn = nn.LSTM(self.input_size, self.hidden_size, batch_first = True)\n",
    "        #^^Expects data as: (batch_size,sequence,features)\n",
    "        self.fc1 = nn.Linear(self.hidden_size, 32)\n",
    "        self.fc2 = nn.Linear(32,16)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        #self.linear = nn.Linear(self.hidden_size, 4) #Regression problem.\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1,x.size(0),self.hidden_size)\n",
    "        h0 = h0.cuda()\n",
    "        c0 = torch.zeros(1,x.size(0),self.hidden_size)\n",
    "        c0 = c0.cuda()\n",
    "        out,(h0,c0) = self.rnn(x,(h0,c0))\n",
    "        x = F.relu(out)\n",
    "        x = F.relu(self.fc1(x)) # 2 fully connected layers\n",
    "        x = self.fc2(x)\n",
    "        x = self.sig(x)\n",
    "        pred = x[:,-1,:]\n",
    "        #pred[:,14] = pred[:,14]**6\n",
    "        \n",
    "        return pred\n",
    "    \n",
    "print('Model class created succesfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scuffed training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = list(torch.load(\"data/trainData.pt\"))\n",
    "valData = list(torch.load(\"data/valData.pt\"))\n",
    "#testData = list(torch.load(\"data/testData.pt\"))\n",
    "\n",
    "batchSize = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dnwzsoywdg6O"
   },
   "outputs": [],
   "source": [
    "def GetAccuracy(model, train=False, limit=-1):\n",
    "    if train:\n",
    "        data = trainData\n",
    "    else:\n",
    "        data = valData\n",
    "        \n",
    "    #err = 0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for imgs, labels in torch.utils.data.DataLoader(data, batch_size=batchSize, shuffle=True):\n",
    "        imgs = imgs.cuda()\n",
    "        labels = labels.cuda()\n",
    "          \n",
    "        output = model(imgs)[:,:12]\n",
    "        pred = output==output.max(1, keepdim=True)[0]\n",
    "        pred = pred.float()\n",
    "        \n",
    "        #select index with maximum prediction score\n",
    "        lab = labels[:,:12].view_as(output)\n",
    "        \n",
    "        correct += pred.eq(lab).sum().item()\n",
    "        \n",
    "        #error = abs(output-lab).sum().item()\n",
    "        \n",
    "        #err += error/16\n",
    "        total += imgs.shape[0]*12\n",
    "        #print(total/12)\n",
    "        \n",
    "        if limit > 0 and (total/12) > limit:\n",
    "            break\n",
    "        \n",
    "    #totalError = err / total\n",
    "    accuracy = correct/total\n",
    "    accuracy -= 5/6\n",
    "    accuracy *= 6\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JchuI0fXdj6V"
   },
   "outputs": [],
   "source": [
    "def train(model, batch_size=batchSize, learning_rate=0.001, num_epochs=1, model_name=\"model\"):\n",
    "    trainLoader = torch.utils.data.DataLoader(trainData, batch_size=batch_size)\n",
    "    criterion = nn.MSELoss() \n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate) # Cross-Entropy Loss and SGD are commonly used for classification problems\n",
    "    \n",
    "    dataSize = len(trainData)*num_epochs\n",
    "\n",
    "    iters, losses, train_acc, val_acc = [], [], [], []\n",
    "    \n",
    "    maxVal = 0\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(\"using cuda\")\n",
    "\n",
    "    # training\n",
    "    n = 0 # the number of iterations\n",
    "    for epoch in range(num_epochs):\n",
    "        for imgs, labels in iter(trainLoader):\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                imgs = imgs.cuda()\n",
    "                labels = labels.cuda()\n",
    "            \n",
    "            out = model(imgs)             # forward pass\n",
    "\n",
    "            loss = criterion(out, labels) # compute the total loss\n",
    "            loss.backward()               # backward pass (compute parameter updates)\n",
    "            optimizer.step()              # make the updates for each parameter\n",
    "            optimizer.zero_grad()         # a clean up step for PyTorch\n",
    "\n",
    "            # save the current training information\n",
    "            iters.append(n)\n",
    "            losses.append(float(loss)/batch_size)             # compute *average* loss\n",
    "            \n",
    "            trainAccuracy = GetAccuracy(model, train=True, limit=10000)\n",
    "            train_acc.append(trainAccuracy) # compute training accuracy\n",
    "            \n",
    "            valAccuracy = GetAccuracy(model, train=False)\n",
    "            val_acc.append(valAccuracy)  # compute validation accuracy\n",
    "            \n",
    "            if valAccuracy > maxVal and valAccuracy > 0.2:\n",
    "                maxVal = valAccuracy\n",
    "                torch.save(model.state_dict(), model_name+\".pt\")\n",
    "                print(\"Validation record in iteration {}: {}\".format(n, maxVal)) # save model when validation accuracy is higher than previous runs\n",
    "                \n",
    "            if trainAccuracy > valAccuracy + 0.2: #check for overfitting\n",
    "                break\n",
    "            \n",
    "            \n",
    "            n += 1\n",
    "            if n % 10 == 0:\n",
    "                perc = n*batch_size/dataSize\n",
    "                print(\"{:.2%} complete\".format(perc))\n",
    "\n",
    "    # plotting\n",
    "    plt.title(\"Training Curve\")\n",
    "    plt.plot(iters, losses, label=\"Train\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.title(\"Training Curve\")\n",
    "    plt.plot(iters, train_acc, label=\"Train\")\n",
    "    plt.plot(iters, val_acc, label=\"Validation\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n",
    "    print(\"Final Validation Accuracy: {}\".format(val_acc[-1]))\n",
    "    \n",
    "    return maxModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(2)\n",
    "\n",
    "start = time.time()\n",
    "model = MusicGenerator()\n",
    "model = model.cuda()\n",
    "train(model,num_epochs=21)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old = MusicGenerator().cuda()\n",
    "params = torch.load(\"secondModel.pt\")\n",
    "old.load_state_dict(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(valData, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = torch.Tensor([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss[1] = 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iii = 0\n",
    "scaleNotes = [\"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\"]\n",
    "\n",
    "for a, b in iter(loader): \n",
    "    if iii < 2:\n",
    "        a = a.cuda()\n",
    "        c = old(a)\n",
    "        d = c[:,:12]\n",
    "        e = b[:,:12]\n",
    "        timea = c[:,14].item()*40000\n",
    "        timeb = b[:,14].item()*40000\n",
    "        timea = round(timea)\n",
    "        timeb = round(timeb)\n",
    "        \n",
    "        ti = torch.clone(c)\n",
    "        #ti[:,14] = ti[:,14]**6\n",
    "        \n",
    "        #print(a.cpu())\n",
    "#         print(\"ratio: {}\".format(timeb/timea))\n",
    "#         print(\"pred: {}\".format(timea))\n",
    "#         print(\"correct: {}\".format(timeb))\n",
    "        print(ti)\n",
    "        print()\n",
    "    iii += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(overfitModel.state_dict(),\"secondModel.pt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = MidiFile(\"bigtest.midi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.ticks_per_beat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overfitModel(tinyData[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To help us save the model easier...\n",
    "def get_model_name(name, batch_size, learning_rate, epoch):\n",
    "    \"\"\" Generate a name for the model consisting of all the hyperparameter values\n",
    "\n",
    "    Args:\n",
    "        config: Configuration object containing the hyperparameters\n",
    "    Returns:\n",
    "        path: A string with the hyperparameter name and value concatenated\n",
    "    \"\"\"\n",
    "    path = \"model_{0}_bs{1}_lr{2}_epoch{3}\".format(name,\n",
    "                                                   batch_size,\n",
    "                                                   learning_rate,\n",
    "                                                   epoch)\n",
    "    return path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,data, num_epochs=5, batch_size=64, learning_rate=1e-3):\n",
    "    torch.manual_seed(1000) #Fixed. Make sure we use this throughout...\n",
    "    criterion = nn.MSELoss() # mean square error loss. Compares reconstruction errors entry by entry.\n",
    "    optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                 lr=learning_rate, \n",
    "                                 weight_decay=1e-5) # <-- Sometimes Adam converges faster than SGD\n",
    "    train_loader = torch.utils.data.DataLoader(data, \n",
    "                                               batch_size=batch_size, \n",
    "                                               shuffle=True)\n",
    "    \n",
    "    iters, losses = [], []\n",
    "    \n",
    "    n = 0 # the number of iterations\n",
    "    start_time=time.time() #Start of training.\n",
    "    outputs = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for data in train_loader:\n",
    "            excerpt = data[:-1] # Extracts all but the last note (model will predict last note)\n",
    "            true_note = data[-1] # Extracts the last note.\n",
    "            pred_note = model(excerpt) # Collects next note prediction.\n",
    "            loss = criterion(pred_note, true_note)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad() # Clean up, clean up, everybody, everywhere...\n",
    "\n",
    "                \n",
    "            iters.append(n)\n",
    "            losses.append(float(loss)/batch_size)             # compute *average* loss\n",
    "            \n",
    "            n += 1\n",
    "        \n",
    "        print('Epoch:{}, Loss:{:.4f}'.format(epoch+1, float(loss)))\n",
    "        outputs.append((epoch, true_note, pred_note),)\n",
    "      #Checkpoint the model every epoch\n",
    "        model_path = get_model_name(model.name, batch_size, learning_rate, epoch) #Returns the model name for \n",
    "      #the save file.\n",
    "        print('model_path: ',model_path)\n",
    "        torch.save(model.state_dict(), model_path) #Saves the current model with the weights.\n",
    "        print('model checkpointed')\n",
    "    end_time= time.time()\n",
    "    \n",
    "    \n",
    "      # plotting\n",
    "    plt.title(\"Training Curve\")\n",
    "    plt.plot(iters, losses, label=\"Train\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNMusicGenerator()\n",
    "\n",
    "train(model,data,batch_size = 1,num_epochs = 1,lr = 0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our model is 'tested' with people listening to it, we need to just generate some samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using random noise inputs:\n",
    "\n",
    "x = torch.randn(1, 1, 1) # (Batch_size,sequence,notes) --> Must match the LSTM layer input.\n",
    "\n",
    "song_length = 1 #How many new notes we want the model to generate.\n",
    "\n",
    "start = True\n",
    "for t in range(0,song_length): #Generates t new notes.\n",
    "    new_sample = model(x)\n",
    "    if start:\n",
    "        new_excerpt = torch.cat(x,new_sample) #initializes new_excerpt as the random noise + new note\n",
    "    else:\n",
    "        new_excerpt = torch.cat(new_excerpt,new_sample)\n",
    "    x = torch.cat(x[1:],new_sample) #Update x by throwing out the first note in the sequence and shoving the new note to the end.\n",
    "\n",
    "print('loop done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 229
    },
    "id": "AshJcI5g83Cj",
    "outputId": "67886882-5680-4f53-e401-9d3167d907f0"
   },
   "outputs": [],
   "source": [
    "#Using random noise inputs:\n",
    "model = old\n",
    "\n",
    "test_data = torch.load(\"data/onehot_data/tinyDataOneHot.pt\")\n",
    "#test_data = torch.Tensor(test_data).float()\n",
    "test_loader = torch.utils.data.DataLoader(test_data, \n",
    "                                           batch_size=1, \n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 229
    },
    "id": "AshJcI5g83Cj",
    "outputId": "67886882-5680-4f53-e401-9d3167d907f0"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "x = 0\n",
    "for sample, label in iter(test_loader):\n",
    "    x = sample # (Batch_size,sequence,notes) --> Must match the model layer input. Want it to give me small positive values!\n",
    "    x = x.cuda()\n",
    "    break\n",
    "#print('x.shape: ',x.shape)\n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x.squeeze(0).cpu().detach().numpy()\n",
    "Numpy2Midi(y,\"asreest1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 229
    },
    "id": "AshJcI5g83Cj",
    "outputId": "67886882-5680-4f53-e401-9d3167d907f0"
   },
   "outputs": [],
   "source": [
    "song_length = 50 #How many new notes we want the model to generate.\n",
    "\n",
    "start = True\n",
    "for t in range(0,song_length): #Generates t new notes.\n",
    "    new_sample = model(x)\n",
    "#     print(new_sample.shape)\n",
    "    if start:\n",
    "#         print(new_sample.shape)\n",
    "        new_sample = new_sample.unsqueeze(0)\n",
    "#         print(new_sample.shape)\n",
    "        new_excerpt = torch.cat((x[:,1:,:],new_sample),1) #initializes new_excerpt as the random noise + new note\n",
    "        start = False\n",
    "#         print(new_excerpt.shape)\n",
    "        x = new_excerpt\n",
    "#         print(x)\n",
    "    else:\n",
    "        new_sample = new_sample.unsqueeze(0)\n",
    "        new_excerpt = torch.cat((new_excerpt,new_sample),1)\n",
    "#         print(new_sample.shape)\n",
    "        x = torch.cat((x[:,1:,:],new_sample),1) #Update x by throwing out the first note in the sequence and shoving the new note to the end.\n",
    "#         print(x)\n",
    "        \n",
    "        \n",
    "# print(new_excerpt.shape)\n",
    "print('%% generator loop done %%')\n",
    "# print(new_excerpt.shape)\n",
    "# print('new excerpt type: ',type(new_excerpt))\n",
    "new_excerpt = new_excerpt.cpu()\n",
    "new_excerpt = new_excerpt.detach().numpy()\n",
    "# new_excerpt = new_excerpt.type(torch.int64)\n",
    "print('new excerpt: (Watch for the same notes appearing...)',new_excerpt)\n",
    "new_excerpt = np.array(new_excerpt[0])\n",
    "print('new_excerpt.shape: ',new_excerpt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_excerpt[0])\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Numpy2Midi(new_excerpt,\"asreest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#overfitLoader = torch.utils.data.DataLoader(overfitData, batch_size=overfitBatch, shuffle=False)\n",
    "\n",
    "def OverfitAccuracy(model): # NOT USED - SAME AS ERROR\n",
    "    data = overfitData\n",
    "\n",
    "    err = 0\n",
    "    total = 0\n",
    "    for imgs, labels in torch.utils.data.DataLoader(data, batch_size=overfitBatch):\n",
    "        imgs = imgs.cuda()\n",
    "        labels = labels.cuda()\n",
    "          \n",
    "        output = model(imgs)\n",
    "        #select index with maximum prediction score\n",
    "        lab = labels.view_as(output)\n",
    "        \n",
    "        error = abs(output-lab).sum().item()\n",
    "        \n",
    "        err += error/16\n",
    "        total += imgs.shape[0]\n",
    "    totalError = err / total\n",
    "    return totalError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tinyData = torch.load(\"data/onehot_data/tinyDataOneHot.pt\")\n",
    "# overfitData = tinyData\n",
    "# overfitData = list(overfitData)\n",
    "# overfitBatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def OverfitTrain(model, data, batch_size=overfitBatch, num_epochs=1):\n",
    "    train_loader = torch.utils.data.DataLoader(data, batch_size=overfitBatch)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "    iters, losses, train_acc, val_acc = [], [], [], []\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(\"using cuda\")\n",
    "\n",
    "    # training\n",
    "    n = 0 # the number of iterations\n",
    "    for epoch in range(num_epochs):\n",
    "        for imgs, labels in iter(train_loader):\n",
    "          \n",
    "            if torch.cuda.is_available():\n",
    "                imgs = imgs.cuda()\n",
    "                labels = labels.cuda()\n",
    "              \n",
    "            out = model(imgs)             # forward pass\n",
    "\n",
    "            loss = criterion(out, labels) # compute the total loss\n",
    "            #print(float(loss)/batch_size)\n",
    "            loss.backward()               # backward pass (compute parameter updates)\n",
    "            optimizer.step()              # make the updates for each parameter\n",
    "            optimizer.zero_grad()         # a clean up step for PyTorch\n",
    "\n",
    "            # save the current training information\n",
    "            iters.append(n)\n",
    "            losses.append(float(loss)/batch_size)             # compute *average* loss\n",
    "            train_acc.append(OverfitAccuracy2(model)) # compute training accuracy \n",
    "            n += 1\n",
    "            if n % 1 == 0:\n",
    "                print(n)\n",
    "            \n",
    "\n",
    "    # plotting\n",
    "    plt.title(\"Overfit Curve\")\n",
    "    plt.plot(iters, losses, label=\"Train\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.title(\"Training Curve\")\n",
    "    plt.plot(iters, train_acc, label=\"Train\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Training Note Accuracy\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OverfitAccuracy2(model):\n",
    "    data = overfitData\n",
    "\n",
    "    #err = 0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for imgs, labels in torch.utils.data.DataLoader(data, batch_size=overfitBatch):\n",
    "        imgs = imgs.cuda()\n",
    "        labels = labels.cuda()\n",
    "          \n",
    "        output = model(imgs)[:,:12]\n",
    "        pred = output==output.max(1, keepdim=True)[0]\n",
    "        pred = pred.float()\n",
    "        \n",
    "        #select index with maximum prediction score\n",
    "        lab = labels[:,:12].view_as(output)\n",
    "        \n",
    "        correct += pred.eq(lab).sum().item()\n",
    "        \n",
    "        #error = abs(output-lab).sum().item()\n",
    "        \n",
    "        #err += error/16\n",
    "        total += imgs.shape[0]*12\n",
    "    #totalError = err / total\n",
    "    accuracy = correct/total\n",
    "    accuracy -= 5/6\n",
    "    accuracy *= 6\n",
    "    return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
