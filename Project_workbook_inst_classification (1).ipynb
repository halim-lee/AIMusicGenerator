{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oPQ2oTOyrSiA"
   },
   "source": [
    "# Project File - APS360 Team 25\n",
    "Divided into the following section: \n",
    "# \n",
    "1) Library imports\n",
    "2) Data imports\n",
    "3) Model architecture definition\n",
    "4) Training function definition\n",
    "5) Model training\n",
    "6) Model testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CxCkcc2ArSiA"
   },
   "source": [
    "## Library imports \n",
    "(Place all library imports here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Qdi1ymBrSiA",
    "outputId": "b3f9649f-15e3-45da-b14a-505714afdad9"
   },
   "outputs": [],
   "source": [
    "#KP - I just added the main ones from the labs.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "\n",
    "import time # Tracking model training time.\n",
    "\n",
    "# Install mido for Data importing\n",
    "!pip install mido;\n",
    "import mido\n",
    "from mido import MidiFile, Message, MidiTrack, MetaMessage\n",
    "import os\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I3b7uuDcrqIj",
    "outputId": "eaf04f40-d5ff-40f2-b395-6854c3e36e8e"
   },
   "outputs": [],
   "source": [
    "#Set working directory if required:\n",
    "# os.chdir('D:\\engsci\\year 3\\CLASS\\APS360\\Project') #Sets current working directory!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "755DNUDOrSiB"
   },
   "source": [
    "## Data imports\n",
    "#### MIDI reading functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "UGf_y0zxrSiB"
   },
   "outputs": [],
   "source": [
    "def CountTracks(directory):          #Count files and tracks in folder\n",
    "    trackCount = 0\n",
    "    fileCount = 0\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(\".midi\"):\n",
    "            fileCount += 1\n",
    "            midiDir = MidiFile(directory+\"/\"+file)\n",
    "            for track in midiDir.tracks:\n",
    "                trackCount += 1\n",
    "    print(fileCount+\" files\")\n",
    "    print(trackCount+\" tracks\")\n",
    "\n",
    "    \n",
    "def PrintMessages(mid):                # print midi messages\n",
    "    for i, track in enumerate(mid.tracks):\n",
    "        print('Track {}: {}'.format(i, track.name))\n",
    "        for msg in track:\n",
    "            print(msg)\n",
    "\n",
    "            \n",
    "def PrintSomeMessages(mid):             #print first 200 midi messages\n",
    "    track = mid.tracks[1]\n",
    "    for i,msg in enumerate(track):\n",
    "        if i < 200:\n",
    "            print(msg)\n",
    "            \n",
    "def PrintMetaMessages(mid):             #print fmeta messages\n",
    "    track = mid.tracks[0]\n",
    "    for i,msg in enumerate(track):\n",
    "        print(msg)\n",
    "\n",
    "def cleanupMessages(mid):              #removes non-note messages by force\n",
    "    track = mid.tracks[1]\n",
    "    track2 = []\n",
    "    for msg in track:\n",
    "        if msg.type == \"note_on\":\n",
    "            track2.append(msg)\n",
    "    mid.tracks[1] = track2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2UT23qIIrSiB"
   },
   "source": [
    "#### MIDI to Numpy code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "zsvL0x4krSiB"
   },
   "outputs": [],
   "source": [
    "def Midi2NumpyNoSustain(mid, track0=1):                                #converts to numpy array removing non-note messages\n",
    "    track = mid.tracks[track0]                           #0th track only contains meta-messages, all notes on 1st track\n",
    "    notes = np.empty([0,4])\n",
    "    time = 0\n",
    "    for msg in track:\n",
    "        if msg.type == \"note_on\":                   # only count \"note\" messages - other inputs i.e. foot pedals are ignored\n",
    "            notes = np.append(notes,np.array([[msg.note, msg.velocity, msg.time + time, 0]]),axis=0)         # (note, velocity, time, sustain)\n",
    "            time = 0\n",
    "        elif msg.type == \"note_off\":\n",
    "            notes = np.append(notes,np.array([[msg.note, 0, msg.time + time, 0]]),axis=0)         # (note, velocity, time, sustain)\n",
    "            time = 0        \n",
    "        else:\n",
    "            time += msg.time                        #adjust time when removing other messages\n",
    "    return notes\n",
    "\n",
    "\n",
    "def NumpyGetSustain(note):\n",
    "    notes = np.copy(note)\n",
    "    for i, msg in enumerate(notes):\n",
    "        if msg[1] > 0:                            # if velocity is not 0\n",
    "            j = 1\n",
    "            sustain = 0\n",
    "            while msg[0] != notes[i+j][0]:        # while note values are different\n",
    "                sustain += notes[i+j][2]\n",
    "                j += 1                            #search for next message with same note i.e. message telling that note was released\n",
    "            notes[i,3] = sustain + notes[i+j][2]\n",
    "    time = 0\n",
    "    for i, msg in enumerate(notes):\n",
    "        if msg[1] > 0:\n",
    "            notes[i,2] += time\n",
    "            time = 0\n",
    "        else:\n",
    "            time += msg[2]                        #adjust time\n",
    "    notes = notes[notes[:,1] > 0]                 #filter for notes with positive velocities (note presses)\n",
    "    return notes\n",
    "\n",
    "def NumpyNormalize(note, oneHot=False, full=False):                         #normalize all values to 0-1\n",
    "    notes = np.copy(note)\n",
    "    \n",
    "    if oneHot:\n",
    "        if full:\n",
    "            notes[:,88] /= 128\n",
    "            notes[:,89] /= 40000\n",
    "            notes[:,90] /= 40000\n",
    "        else:\n",
    "            notes[:,12] /= 11\n",
    "            notes[:,13] /= 128\n",
    "            notes[:,14] /= 40000\n",
    "            notes[:,15] /= 40000\n",
    "    else:\n",
    "        notes[:,0] /= 128\n",
    "        notes[:,1] /= 128\n",
    "        notes[:,2] /= 40000\n",
    "        notes[:,3] /= 40000       \n",
    "    return notes\n",
    "\n",
    "def NumpyOneHot(note):\n",
    "    notes = np.copy(note)\n",
    "    oneHot = np.zeros([len(notes),16])\n",
    "    oneHot[:, 13:] = notes[:, 1:]\n",
    "    names = notes[:,0]\n",
    "    namesOct = names%12\n",
    "    oneHot[:,12] = (names-(namesOct))/12\n",
    "    \n",
    "    for i, name in enumerate(namesOct):\n",
    "        oneHot[i,name.astype(int)] = 1\n",
    "    \n",
    "    return oneHot\n",
    "\n",
    "def NumpyNotesOneHot(note):\n",
    "    notes = np.copy(note)\n",
    "    \n",
    "    oneHot = np.zeros([len(notes),91])\n",
    "    oneHot[:, 88:] = notes[:, 1:]\n",
    "    names = notes[:,0]-21\n",
    "    #namesOct = names%12\n",
    "    #oneHot[:,12] = (names-(namesOct))/12\n",
    "    \n",
    "    for i, name in enumerate(names):\n",
    "        oneHot[i,name.astype(int)] = 1\n",
    "    \n",
    "    return oneHot\n",
    "\n",
    "def Midi2Numpy(path, oneHot=False, track0=1): # full midi to numpy conversion\n",
    "    mid = MidiFile(path)\n",
    "    notes = Midi2NumpyNoSustain(mid, track0=track0)\n",
    "    cleanNotes = NumpyGetSustain(notes)\n",
    "    \n",
    "    if oneHot:\n",
    "        cleanNotes = NumpyOneHot(cleanNotes)\n",
    "    \n",
    "    normNotes = NumpyNormalize(cleanNotes, oneHot=oneHot)\n",
    "    return normNotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQ3C4NpgrSiB"
   },
   "source": [
    "#### Numpy to MIDI code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "FcyTTyH-rSiB"
   },
   "outputs": [],
   "source": [
    "def NumpyDenormalize(note): # interpret all values from 0-1 to normal values\n",
    "    notes = np.copy(note)    \n",
    "    if notes.shape[1] == 16: # if encode as one-hot\n",
    "        notes[:,12] *= 11 # octave\n",
    "        notes[:,13] *= 128 # vel\n",
    "        notes[:,14] *= 40000 # time\n",
    "        notes[:,15] *= 40000 # sustain\n",
    "        \n",
    "        notes = NumpyEncode(notes) #encode back as original 4-variable format\n",
    "        \n",
    "    elif notes.shape[1] == 91: # if encoded as one-hot w/o octave\n",
    "        notes[:,88] *= 128\n",
    "        notes[:,89] *= 40000\n",
    "        notes[:,90] *= 40000\n",
    "        \n",
    "        #print(notes)\n",
    "        \n",
    "        notes = NumpyEncodeNotes(notes)\n",
    "        \n",
    "    else:\n",
    "        notes[:,0] *= 128\n",
    "        notes[:,1] *= 128\n",
    "        notes[:,2] *= 40000\n",
    "        notes[:,3] *= 40000       \n",
    "    return notes.astype(int)\n",
    "\n",
    "def NumpyEncode(note): # convert back from one-hot encoding\n",
    "    notes = np.copy(note)    \n",
    "    encoded = np.zeros([len(notes),4]) # create array   \n",
    "    encoded[:, 1:] = notes[:, 13:] # set vel/time/sustain\n",
    "    encoded[:, 0] = notes[:,12]*12 # add octave value\n",
    "    \n",
    "    for i in range(len(notes)):\n",
    "        encoded[i,0] += np.argmax(notes[i,:12])\n",
    "    \n",
    "    return encoded\n",
    "\n",
    "def NumpyEncodeNotes(note): # convert back from one-hot encoding\n",
    "    notes = np.copy(note)    \n",
    "    encoded = np.zeros([len(notes),4])\n",
    "    \n",
    "    encoded[:, 1:] = notes[:, 88:] # set vel/time/sustain\n",
    "    \n",
    "    for i in range(len(notes)):\n",
    "        encoded[i,0] += np.argmax(notes[i,:88])+21\n",
    "    \n",
    "    return encoded\n",
    "\n",
    "def NumpySequence(notes): # put all notes into a \"timeline\" i.e.: time values of [10, 20, 10, 30] become [10, 30, 40, 70]\n",
    "    sequenced = np.copy(notes)                      # this allows us to easily add vel=0 notes in any order since we can later sort them by time\n",
    "    for i, msg in enumerate(sequenced):\n",
    "        if i > 0:\n",
    "            sequenced[i,2] += sequenced[i-1,2]\n",
    "    return sequenced\n",
    "\n",
    "def NumpyAddOffNotes(sequenced): # add vel=0 notes from sustain into sequenced timeline\n",
    "    withOff = np.copy(sequenced)\n",
    "    for msg in sequenced:\n",
    "        offNote = np.array([[msg[0], 0, msg[2] + msg[3], 0]])\n",
    "        withOff = np.append(withOff, offNote, axis=0)\n",
    "    #withOff = np.sort(withOff,axis=0)\n",
    "    withOff = withOff[withOff[:,2].argsort()] # sort by time\n",
    "    return withOff\n",
    "\n",
    "def NumpyUnsequence(notes): # revert time value to \"time since last message\"\n",
    "    unsequenced = np.copy(notes)\n",
    "    for i, msg in reversed(list(enumerate(unsequenced))):\n",
    "        unsequenced[i,3] = 0\n",
    "        if i > 0:\n",
    "            unsequenced[i,2] -= unsequenced[i-1,2]\n",
    "    return unsequenced\n",
    "\n",
    "def Numpy2MidiDirect(array):    #make MIDI object from numpy\n",
    "    #Start with initializing a new Mido Track:\n",
    "    mid = MidiFile()\n",
    "    track0 = MidiTrack()\n",
    "    track1 = MidiTrack()\n",
    "    \n",
    "    track0.append(MetaMessage('set_tempo', tempo=500000, time=0)) #MetaMessages not necessary but are present in used files\n",
    "    track0.append(MetaMessage('time_signature', numerator=4, denominator=4, clocks_per_click=24, notated_32nd_notes_per_beat=8, time=0))\n",
    "    track0.append(MetaMessage('end_of_track', time=1))\n",
    "    \n",
    "    track1.append(Message('program_change', channel=0, program=0, time=0))\n",
    "    \n",
    "    for i,note in enumerate(array):         # Get the index and the note. Array must be int array\n",
    "        j = 1\n",
    "        track1.append(Message('note_on',note = array[i,0], velocity = array[i,1],time = array[i,2])) # Add the note to the track.\n",
    "\n",
    "    mid.tracks.append(track0)\n",
    "    mid.tracks.append(track1)\n",
    "    return mid\n",
    "\n",
    "def Numpy2Midi(notes, name): # full numpy to midi conversion, saving result to [name].midi\n",
    "    denorm = NumpyDenormalize(notes)\n",
    "    seq = NumpySequence(denorm)\n",
    "    off = NumpyAddOffNotes(seq)\n",
    "    unseq = NumpyUnsequence(off)\n",
    "    mid = Numpy2MidiDirect(unseq)\n",
    "    mid.save(name + \".midi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "OCUYyBiIrSiB"
   },
   "outputs": [],
   "source": [
    "def splitTrack(midiFileName, inputDir, outputDir):\n",
    "    mid = MidiFile(inputDir+midiFileName+\".midi\")\n",
    "    for t, track in enumerate(mid.tracks):\n",
    "        program, channel = findInstrument(track)        \n",
    "        if len(track) < 200 or program == -1:\n",
    "            continue\n",
    "        trackMidi = copy.copy(mid)\n",
    "        indices = [t]\n",
    "        trackMidi.tracks = [trackMidi.tracks[x] for x in indices]\n",
    "        #trackMidi.tracks.append(track)\n",
    "        trackMidi.save(outputDir + midiFileName + \"_prog{:0>3d}_chan{:0>2d}.midi\".format(program,channel))\n",
    "\n",
    "def splitAllTracks(inputDir, outputDir, first=0): # very bad code -  doesnt remove the .midi in the middle lol\n",
    "    for i,f in enumerate(os.listdir(inputDir)):\n",
    "        if i >= first:\n",
    "            if len(f) <7:\n",
    "                continue\n",
    "            splitTrack(f[:7],inputDir,outputDir)\n",
    "\n",
    "            if i % 1 == 0:\n",
    "                print(f)\n",
    "        \n",
    "def findInstrument(track):\n",
    "    count = 0\n",
    "    infoMsg = 0\n",
    "    \n",
    "    for msg in track:\n",
    "        if msg.type == \"program_change\":\n",
    "            count += 1\n",
    "            infoMsg = msg\n",
    "    \n",
    "    if count >= 1:\n",
    "        if infoMsg.channel == 9 or count == 1:\n",
    "            return infoMsg.program, infoMsg.channel\n",
    "        else: \n",
    "            return -1, -1\n",
    "    else:\n",
    "        return -1, -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "iP4lojMgrSiB",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#splitAllTracks(\"data/jazz/\",\"data/jazz/tracks/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vTtFiHvFrSiB"
   },
   "source": [
    "#### Generatng tensor dataset from CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Vxt1UBhHrSiB"
   },
   "outputs": [],
   "source": [
    "def Numpy2Dataset(notes, tgt, num=100,skip=200): # make list of sumpy arrays\n",
    "    samples = []\n",
    "    targets = []\n",
    "    i = 0\n",
    "    while i+num <= len(notes):\n",
    "        samples.append(notes[i:i+num])\n",
    "        targets.append(tgt)\n",
    "        i += skip\n",
    "    return samples, targets\n",
    "\n",
    "def SampleAllNumpy(dataPath): # generate samples from all saved CSVs\n",
    "    allSamples = []\n",
    "    allTargets = []\n",
    "\n",
    "    for i,f in enumerate(os.listdir(dataPath)):\n",
    "        notes = np.genfromtxt(dataPath+f, delimiter=',')\n",
    "        tgt = GetGroup(f)\n",
    "                             \n",
    "        samples, targets = Numpy2Dataset(notes, tgt)\n",
    "        allSamples += samples\n",
    "        allTargets += targets\n",
    "        if i % 100 == 0:\n",
    "            print(i)\n",
    "            \n",
    "    random.seed(0)\n",
    "    random.shuffle(allSamples)\n",
    "    random.seed(0)\n",
    "    random.shuffle(allTargets) # shuffle samples and targets in the exact same way\n",
    "    \n",
    "    return allSamples, allTargets\n",
    "\n",
    "def SaveSamplesTensor(samples, targets, outputPath, name=\"Notes_Dataset\"): # save tensor\n",
    "    tens = torch.Tensor(samples)\n",
    "    targ = torch.Tensor(targets)\n",
    "    dataset = TensorDataset(tens,targ)\n",
    "    torch.save(dataset, outputPath+name+\".pt\")\n",
    "    return tens   \n",
    "\n",
    "def SaveAllSamples(dataPath, outputPath, name=\"Notes_Dataset\"): # save dataset tensor\n",
    "    samples, targets = SampleAllNumpy(dataPath)\n",
    "    SaveSamplesTensor(samples, targets, outputPath, name)\n",
    "    \n",
    "def SplitSamples(dataset, ranges):\n",
    "    torch.maual_seed(0)\n",
    "    trainData, valData, testData = random_split(oneHotDataset, splitRange)\n",
    "    return trainData, valData, testData "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "DGM_cpI2rSiB"
   },
   "outputs": [],
   "source": [
    "def ProgramGroup(program, channel):\n",
    "    if channel == 9:\n",
    "        return 0 # drums\n",
    "    if program < 8:\n",
    "        return 1 # piano\n",
    "    if program < 16:\n",
    "        return 8 # pitched percussion\n",
    "    if program < 24:\n",
    "        return 7 # organ\n",
    "    if program < 32:\n",
    "        return 3 # guitar\n",
    "    if program < 40:\n",
    "        return 2 # bass\n",
    "    if program < 48:\n",
    "        return 9 # string\n",
    "    if program < 56:\n",
    "        return 10 # ensemble\n",
    "    if program < 64:\n",
    "        return 4 # brass \n",
    "    if program < 72:\n",
    "        return 5 # reed\n",
    "    if program < 80:\n",
    "        return 11 # pipe\n",
    "    if program < 88:\n",
    "        return 6 # synth lead\n",
    "    if program < 96:\n",
    "        return 12 # synth pad\n",
    "    if program < 104:\n",
    "        return 13 # synth efects\n",
    "    if program < 112:\n",
    "        return 14 # ethnic\n",
    "    if program < 120:\n",
    "        return 15 # percusson\n",
    "    else:\n",
    "        return 16 # other \n",
    "    \n",
    "def GetProgram(name):\n",
    "    prog = name[12:15]\n",
    "    chan = name[20:22]\n",
    "    return int(prog), int(chan)\n",
    "\n",
    "def GetGroup(name):\n",
    "    prog, chan = GetProgram(name)\n",
    "    group = ProgramGroup(prog, chan)\n",
    "    return(group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EcsmXvAarSiB"
   },
   "source": [
    "#### Bulk data conversion code - COMMENT OUT IF NOT IN USE!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "vKGMTqwurSiB"
   },
   "outputs": [],
   "source": [
    "#SaveAllSamples(\"data/jazz/tracks_numpy/train/\",\"data/\",\"trainDataClass\") #save all into tensor\n",
    "#SaveAllSamples(\"data/jazz/tracks_numpy/val/\",\"data/\",\"valDataClass\") #save all into tensor\n",
    "#SaveAllSamples(\"data/jazz/tracks_numpy/test/\",\"data/\",\"testDataClass\") #save all into tensor\n",
    "\n",
    "# oneHotDataset = torch.load(\"data/onehot_data/onehot.pt\")\n",
    "\n",
    "# splitProp = np.array([0.9, 0.05 , 0.05]) # 90/5/5% split\n",
    "# splitRange = len(oneHotDataset)*splitProp\n",
    "# splitRange[0] += 1                           # so numbers add up\n",
    "# splitRange = splitRange.astype(int)\n",
    "\n",
    "# length = len(oneHotDataset)\n",
    "# a = 0.9*length\n",
    "# a = int(a)\n",
    "\n",
    "# b = 0.95*length\n",
    "# b = int(b)\n",
    "\n",
    "# tiny = oneHotDataset[:30]\n",
    "# train = oneHotDataset[:a]\n",
    "# val = oneHotDataset[a:b]\n",
    "# test = oneHotDataset[b:]\n",
    "\n",
    "# tinyData = TensorDataset(tiny[0].clone(), tiny[1].clone())\n",
    "# trainData = TensorDataset(train[0].clone(),train[1].clone())\n",
    "# valData = TensorDataset(val[0].clone(),val[1].clone())\n",
    "# testData = TensorDataset(test[0].clone(),test[1].clone())\n",
    "\n",
    "# torch.save(tinyData,\"data/onehot_data/tinyDataOneHot.pt\")\n",
    "# torch.save(trainData,\"data/onehot_data/trainDataOneHot.pt\")\n",
    "# torch.save(valData,\"data/onehot_data/valDataOneHot.pt\")\n",
    "# torch.save(testData,\"data/onehot_data/testDataOneHot.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Ssp85azWrSiC"
   },
   "outputs": [],
   "source": [
    "#a = torch.load(\"data/va.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "id": "63avpbMHrSiC",
    "outputId": "38903c44-8edc-4f0b-9005-213cafdb812e"
   },
   "outputs": [],
   "source": [
    "# for img, label in iter(a):\n",
    "#     #print(img)\n",
    "#     print(label)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "dHJs765krSiC"
   },
   "outputs": [],
   "source": [
    "# IMPORTANT: COMMENT OUT IF NOT IN USE TO AVOID ACCIDENTS!!!!!!!\n",
    "\n",
    "# Getting CSVs from MIDI data and processed data from CSVs\n",
    "# Processed MIDI does not contain program messages and so are a good measure of what output SHOULD look like in a perfect world\n",
    "\n",
    "# dataPath = \"data/jazz/tracks/\"\n",
    "# outputPath = \"data/jazz/tracks_numpy/\"\n",
    "# #processedPath = \"data/MIDI_files_processed/\"\n",
    "\n",
    "# for i,f in enumerate(os.listdir(dataPath)):\n",
    "#     if i > 2700:\n",
    "#         notes = Midi2Numpy(dataPath+f,track0=0)\n",
    "#         np.savetxt(outputPath + f[:22]+\".csv\",notes,delimiter=\",\")\n",
    "#     #Numpy2Midi(notes, processedPath + \"MIDI_{:04d}\".format(i))\n",
    "#     #break\n",
    "    \n",
    "#     if i % 200 == 0:\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "GmrcKT1-rSiC"
   },
   "outputs": [],
   "source": [
    "# IMPORTANT: COMMENT OUT IF NOT IN USE TO AVOID ACCIDENTS!!!!!!!\n",
    "\n",
    "# Getting CSVs from MIDI data and processed data from CSVs\n",
    "# Processed MIDI does not contain program messages and so are a good measure of what output SHOULD look like in a perfect world\n",
    "\n",
    "# dataPath = \"data/jazz/tracks/\"\n",
    "# outputPath = \"data/jazz/tracks_numpy/\"\n",
    "# #processedPath = \"data/MIDI_files_processed/\"\n",
    "\n",
    "# for i,f in enumerate(os.listdir(dataPath)):\n",
    "#     if i == 47:\n",
    "#         print(f)\n",
    "#         testMidi = MidiFile(dataPath+f)\n",
    "#         #PrintMessages(testMidi)\n",
    "#         print(GetGroup(f))\n",
    "#     #Numpy2Midi(notes, processedPath + \"MIDI_{:04d}\".format(i))\n",
    "#     #break\n",
    "    \n",
    "#     if i % 100 == 0:\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "r4lW9eKUrSiC"
   },
   "outputs": [],
   "source": [
    "# dataPath = \"data/numpy_files/\"  # one-hot encoding on CSVs\n",
    "# outputPath = \"data/numpy_full/\"\n",
    "\n",
    "# for i,f in enumerate(os.listdir(dataPath)):\n",
    "#     notes = np.genfromtxt(dataPath+f, delimiter=',')\n",
    "#     notes = NumpyDenormalize(notes)\n",
    "#     notes = NumpyNotesOneHot(notes)\n",
    "#     notes = NumpyNormalize(notes, oneHot=True, full=True)\n",
    "#     np.savetxt(outputPath + \"MIDI_{:04d}.csv\".format(i),notes,delimiter=\",\")\n",
    "#     if i % 100 == 0:\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f0fsM7MtrSiC"
   },
   "source": [
    "## Baseline Model Code\n",
    "#### getting available notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3cqmkQTqrSiC"
   },
   "source": [
    "## Model architecture definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eiA0KsAkrSiC"
   },
   "source": [
    "Set the hyperparameters below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f4gpkIALrSiC",
    "outputId": "48c295e0-fcac-4b7a-aa4f-536bf2bef54d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model class created succesfully\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, n_features, n_classes, n_hidden, n_layers):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.name = \"LSTMClassifier\"\n",
    "        self.n_features, self.n_classes, self.n_hidden, self.n_layers = n_classes, n_hidden, n_layers, n_features\n",
    "        self.lstm = nn.LSTM(n_features, n_hidden, n_layers, batch_first=True)\n",
    "        self.fc = torch.nn.Linear(2*n_hidden, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward propagate the RNN\n",
    "        h0 = torch.zeros(self.n_layers,x.size(0),self.n_hidden)\n",
    "        c0 = torch.zeros(self.n_layers,x.size(0),self.n_hidden)\n",
    "        if use_cuda and torch.cuda.is_available():\n",
    "            c0 = c0.cuda()\n",
    "            h0 = h0.cuda()\n",
    "        out, _ = self.lstm(x)\n",
    "        # Pass the output of the last time step to the classifier\n",
    "        out = torch.cat([torch.max(out, dim=1)[0], \n",
    "                    torch.mean(out, dim=1)], dim=1) #Combine max and mean\n",
    "        output = self.fc(out)\n",
    "        return output\n",
    "\n",
    "print('Model class created succesfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5D2idmcbrSiD"
   },
   "source": [
    "## Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "G5ENRYH9rSiD"
   },
   "outputs": [],
   "source": [
    "#To help us save the model easier...\n",
    "def get_model_name(name, batch_size, learning_rate, epoch):\n",
    "    \"\"\" Generate a name for the model consisting of all the hyperparameter values\n",
    "\n",
    "    Args:\n",
    "        config: Configuration object containing the hyperparameters\n",
    "    Returns:\n",
    "        path: A string with the hyperparameter name and value concatenated\n",
    "    \"\"\"\n",
    "    path = \"model_{0}_bs{1}_lr{2}_epoch{3}\".format(name,\n",
    "                                                   batch_size,\n",
    "                                                   learning_rate,\n",
    "                                                   epoch)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "GLOGDWmrubIm"
   },
   "outputs": [],
   "source": [
    "def get_accuracy(model, data_loader): #Accuracy on note selection...\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    i = 0\n",
    "    for sample in data_loader:\n",
    "        inputs, labels = sample\n",
    "        if use_cuda and torch.cuda.is_available():\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "        output = model(inputs)\n",
    "        pred = output.max(1, keepdim=True)[1]\n",
    "        if i%100 == 0:\n",
    "            print(pred)\n",
    "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "        total += len(labels)\n",
    "        i += 1\n",
    "    return (correct / total)*100\n",
    "\n",
    "def get_loss(model, data_loader, criterion):\n",
    "    total_loss = 0\n",
    "    for sample in data_loader:\n",
    "        inputs, labels = sample\n",
    "        if use_cuda and torch.cuda.is_available():\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "        output = model(inputs)\n",
    "        # Get loss\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Sum up loss\n",
    "        total_loss += float(loss)\n",
    "        \n",
    "    lossVal = total_loss / len(inputs)\n",
    "    return lossVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Fpju80lNTuoE"
   },
   "outputs": [],
   "source": [
    "# Training Curve\n",
    "def plot_training_curve(accLoss, train, val):\n",
    "    \"\"\" Plots the training curve for a model's train/validation loss or accuracy.\n",
    "\n",
    "    Args:\n",
    "        accLoss: \"Accuracy\" or \"Loss\"\n",
    "        train: train data\n",
    "        val: validation data\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    titleStr = \"Train vs Validation \" + accLoss\n",
    "    plt.title(titleStr)\n",
    "    n = len(train) # number of epochs\n",
    "    plt.plot(range(1,n+1), train, label=\"Train\")\n",
    "    plt.plot(range(1,n+1), val, label=\"Validation\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(accLoss)\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "8KDJooOSVCTi"
   },
   "outputs": [],
   "source": [
    "def train(model, train_dataset, val_dataset, num_epochs=5, batch_size=64, learning_rate=1e-3):\n",
    "    torch.manual_seed(1000) #Fixed. Make sure we use this throughout...\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                 lr=learning_rate, weight_decay=0.001)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    start_time=time.time() #Start of training\n",
    "\n",
    "    train_losses, train_accs, val_losses, val_accs = [], [], [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, data in enumerate(train_loader):\n",
    "            inputs, labels = data\n",
    "            if use_cuda and torch.cuda.is_available():\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "#             print('labels: ',labels)\n",
    "            out = model(inputs)             # forward pass\n",
    "#             print(out.shape)\n",
    "            loss = criterion(out, labels) # compute the total loss\n",
    "\n",
    "            loss.backward()               # backward pass (compute parameter updates)\n",
    "            optimizer.step()              # make the updates for each parameter\n",
    "            optimizer.zero_grad()         # a clean up step for PyTorch\n",
    "\n",
    "            loss = float(loss)/batch_size             # compute *average* loss\n",
    "\n",
    "        train_acc = get_accuracy(model, train_loader)\n",
    "        val_loss = get_loss(model, val_loader, criterion)\n",
    "        val_acc =get_accuracy(model, val_loader)\n",
    "\n",
    "        print('Epoch: {} - Train loss: {:.4f}, Validation loss: {:.4f}, Train accuracy: {:.2f}%, Validation accuracy: {:.2f}%'.format(\n",
    "                            epoch+1, float(loss), float(val_loss), float(train_acc), float(val_acc)))\n",
    "        \n",
    "        train_losses.append(loss)             # compute *average* loss\n",
    "        train_accs.append(train_acc)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accs.append(val_acc)\n",
    "\n",
    "    #Save the file current model with the weights\n",
    "    model_path = get_model_name(model.name, batch_size, learning_rate, num_epochs)\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    end_time= time.time()\n",
    "\n",
    "    return train_losses, train_accs, val_losses, val_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "U5q-SKT-rSiD"
   },
   "outputs": [],
   "source": [
    "def get_class_binary(dataset,label_1,label_2):\n",
    "    list_data = list(dataset)\n",
    "    data = []\n",
    "    label = []\n",
    "\n",
    "    for sample in list_data:\n",
    "        data.append((sample[0]).detach().numpy())\n",
    "        label.append((sample[1]).detach().numpy())\n",
    "\n",
    "    data = np.array(data)\n",
    "    label = np.array(label)\n",
    "\n",
    "    # Grab data that are classified as 0 or 1\n",
    "    class_0_1_data = data[np.where(np.logical_or(label == label_1, label == label_2))]\n",
    "    class_0_1_label = label[np.where(np.logical_or(label == label_1, label == label_2))]\n",
    "\n",
    "    # Prevent type errors\n",
    "    out_dataset = TensorDataset(torch.tensor(class_0_1_data).float(), torch.tensor(class_0_1_label).long())\n",
    "    return out_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_3(dataset,label_1,label_2,label_3): #For any 3 classes.\n",
    "    list_data = list(dataset)\n",
    "    data = []\n",
    "    label = []\n",
    "\n",
    "    for sample in list_data:\n",
    "        data.append((sample[0]).detach().numpy())\n",
    "        label.append((sample[1]).detach().numpy())\n",
    "    \n",
    "    data = np.array(data)\n",
    "    label = np.array(label)\n",
    "#     print(label)\n",
    "    # Grab data that are classified as 0 or 1\n",
    "    class_0_1_data = data[np.where(np.logical_or(np.logical_or((label == label_1), (label == label_2)), (label == label_3)))]\n",
    "    class_0_1_label = label[np.where(np.logical_or(np.logical_or((label == label_1), (label == label_2)), (label == label_3)))]\n",
    "    print(class_0_1_label)\n",
    "    # Prevent type errors\n",
    "    out_dataset = TensorDataset(torch.tensor(class_0_1_data).float(), torch.tensor(class_0_1_label).long())\n",
    "    return out_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_9(dataset,label_1,label_2,label_3,label_4,label_5,label_6,label_7,label_8,label_9): #For any 9 classes.\n",
    "    list_data = list(dataset)\n",
    "    data = []\n",
    "    label = []\n",
    "\n",
    "    for sample in list_data:\n",
    "        data.append((sample[0]).detach().numpy())\n",
    "        label.append((sample[1]).detach().numpy())\n",
    "    \n",
    "    data = np.array(data)\n",
    "    label = np.array(label)\n",
    "#     print(label)\n",
    "    # Grab data that are classified as 0 or 1\n",
    "    class_0_1_data = data[np.where(np.logical_or(np.logical_or(np.logical_or(np.logical_or(np.logical_or(np.logical_or(np.logical_or(np.logical_or((label == label_1), (label == label_2)), (label == label_3)),label==label_4),label==label_5),label==label_6),label==label_7),label==label_8),label==label_9))]\n",
    "    class_0_1_label = label[np.where(np.logical_or(np.logical_or(np.logical_or(np.logical_or(np.logical_or(np.logical_or(np.logical_or(np.logical_or((label == label_1), (label == label_2)), (label == label_3)),label==label_4),label==label_5),label==label_6),label==label_7),label==label_8),label==label_9))]\n",
    "    print(class_0_1_label)\n",
    "    # Prevent type errors\n",
    "    out_dataset = TensorDataset(torch.tensor(class_0_1_data).float(), torch.tensor(class_0_1_label).long())\n",
    "    return out_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_8(dataset,label_1,label_2,label_3,label_4,label_5,label_6,label_7,label_8): #For any 8 classes.\n",
    "    list_data = list(dataset)\n",
    "    data = []\n",
    "    label = []\n",
    "\n",
    "    for sample in list_data:\n",
    "        data.append((sample[0]).detach().numpy())\n",
    "        label.append((sample[1]).detach().numpy())\n",
    "    \n",
    "    data = np.array(data)\n",
    "    label = np.array(label)\n",
    "#     print(label)\n",
    "    # Grab data that are classified as 0 or 1\n",
    "    class_0_1_data = data[np.where(np.logical_or(np.logical_or(np.logical_or(np.logical_or(np.logical_or(np.logical_or(np.logical_or((label == label_1), (label == label_2)), (label == label_3)),label==label_4),label==label_5),label==label_6),label==label_7),label==label_8))]\n",
    "    class_0_1_label = label[np.where(np.logical_or(np.logical_or(np.logical_or(np.logical_or(np.logical_or(np.logical_or(np.logical_or((label == label_1), (label == label_2)), (label == label_3)),label==label_4),label==label_5),label==label_6),label==label_7),label==label_8))]\n",
    "    print(class_0_1_label)\n",
    "    # Prevent type errors\n",
    "    out_dataset = TensorDataset(torch.tensor(class_0_1_data).float(), torch.tensor(class_0_1_label).long())\n",
    "    return out_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_7(dataset,label_1,label_2,label_3,label_4,label_5,label_6,label_7): #For any 7 classes.\n",
    "    list_data = list(dataset)\n",
    "    data = []\n",
    "    label = []\n",
    "\n",
    "    for sample in list_data:\n",
    "        data.append((sample[0]).detach().numpy())\n",
    "        label.append((sample[1]).detach().numpy())\n",
    "    \n",
    "    data = np.array(data)\n",
    "    label = np.array(label)\n",
    "#     print(label)\n",
    "    # Grab data that are classified as 0 or 1\n",
    "    class_0_1_data = data[np.where(np.logical_or(np.logical_or(np.logical_or(np.logical_or(np.logical_or(np.logical_or((label == label_1), (label == label_2)), (label == label_3)),label==label_4),label==label_5),label==label_6),label==label_7))]\n",
    "    class_0_1_label = label[np.where(np.logical_or(np.logical_or(np.logical_or(np.logical_or(np.logical_or(np.logical_or((label == label_1), (label == label_2)), (label == label_3)),label==label_4),label==label_5),label==label_6),label==label_7))]\n",
    "    print(class_0_1_label)\n",
    "    # Prevent type errors\n",
    "    out_dataset = TensorDataset(torch.tensor(class_0_1_data).float(), torch.tensor(class_0_1_label).long())\n",
    "    return out_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_6(dataset,label_1,label_2,label_3,label_4,label_5,label_6): #For any 6 classes.\n",
    "    list_data = list(dataset)\n",
    "    data = []\n",
    "    label = []\n",
    "\n",
    "    for sample in list_data:\n",
    "        data.append((sample[0]).detach().numpy())\n",
    "        label.append((sample[1]).detach().numpy())\n",
    "    \n",
    "    data = np.array(data)\n",
    "    label = np.array(label)\n",
    "#     print(label)\n",
    "    # Grab data that are classified as 0 or 1\n",
    "    class_0_1_data = data[np.where(np.logical_or(np.logical_or(np.logical_or(np.logical_or(np.logical_or((label == label_1), (label == label_2)), (label == label_3)),label==label_4),label==label_5),label==label_6))]\n",
    "    class_0_1_label = label[np.where(np.logical_or(np.logical_or(np.logical_or(np.logical_or(np.logical_or((label == label_1), (label == label_2)), (label == label_3)),label==label_4),label==label_5),label==label_6))]\n",
    "    print(class_0_1_label)\n",
    "    # Prevent type errors\n",
    "    out_dataset = TensorDataset(torch.tensor(class_0_1_data).float(), torch.tensor(class_0_1_label).long())\n",
    "    return out_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_5(dataset,label_1,label_2,label_3,label_4,label_5): #For any 5 classes.\n",
    "    list_data = list(dataset)\n",
    "    data = []\n",
    "    label = []\n",
    "\n",
    "    for sample in list_data:\n",
    "        data.append((sample[0]).detach().numpy())\n",
    "        label.append((sample[1]).detach().numpy())\n",
    "    \n",
    "    data = np.array(data)\n",
    "    label = np.array(label)\n",
    "#     print(label)\n",
    "    # Grab data that are classified as 0 or 1\n",
    "    class_0_1_data = data[np.where(np.logical_or(np.logical_or(np.logical_or(np.logical_or((label == label_1), (label == label_2)), (label == label_3)),label==label_4),label==label_5))]\n",
    "    class_0_1_label = label[np.where(np.logical_or(np.logical_or(np.logical_or(np.logical_or((label == label_1), (label == label_2)), (label == label_3)),label==label_4),label==label_5))]\n",
    "    print(class_0_1_label)\n",
    "    # Prevent type errors\n",
    "    out_dataset = TensorDataset(torch.tensor(class_0_1_data).float(), torch.tensor(class_0_1_label).long())\n",
    "    return out_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_4(dataset,label_1,label_2,label_3,label_4): #For any 4 classes.\n",
    "    list_data = list(dataset)\n",
    "    data = []\n",
    "    label = []\n",
    "\n",
    "    for sample in list_data:\n",
    "        data.append((sample[0]).detach().numpy())\n",
    "        label.append((sample[1]).detach().numpy())\n",
    "    \n",
    "    data = np.array(data)\n",
    "    label = np.array(label)\n",
    "#     print(label)\n",
    "    # Grab data that are classified as 0 or 1\n",
    "    class_0_1_data = data[np.where(np.logical_or(np.logical_or(np.logical_or((label == label_1), (label == label_2)), (label == label_3)),label==label_4))]\n",
    "    class_0_1_label = label[np.where(np.logical_or(np.logical_or(np.logical_or((label == label_1), (label == label_2)), (label == label_3)),label==label_4))]\n",
    "    print(class_0_1_label)\n",
    "    # Prevent type errors\n",
    "    out_dataset = TensorDataset(torch.tensor(class_0_1_data).float(), torch.tensor(class_0_1_label).long())\n",
    "    return out_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class(dataset):\n",
    "    list_data = list(dataset)\n",
    "    data = []\n",
    "    label = []\n",
    "\n",
    "    for sample in list_data:\n",
    "        data.append((sample[0]).detach().numpy())\n",
    "        label.append((sample[1]).detach().numpy())\n",
    "    \n",
    "    data = np.array(data)\n",
    "    label = np.array(label)\n",
    "#     print(label)\n",
    "    # Grab data that are classified as 0 or 1,2,3,4,5,6,7,8,9... Other classes have 0 samples.\n",
    "    class_0_1_data = data[np.where(np.logical_or(np.logical_or(np.logical_or(np.logical_or(np.logical_or(np.logical_or(np.logical_or(np.logical_or(np.logical_or((label == 0), (label == 1)), (label == 2)),label==4),label==5),label==6),label==7),label==8),label==9),label==3))]\n",
    "    class_0_1_label = label[np.where(np.logical_or(np.logical_or(np.logical_or(np.logical_or(np.logical_or(np.logical_or(np.logical_or(np.logical_or(np.logical_or((label == 0), (label == 1)), (label == 2)),label==4),label==5),label==6),label==7),label==8),label==9),label==3))]\n",
    "    print(class_0_1_label)\n",
    "    # Prevent type errors\n",
    "    out_dataset = TensorDataset(torch.tensor(class_0_1_data).float(), torch.tensor(class_0_1_label).long())\n",
    "    return out_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "DyDP2xejwnXc"
   },
   "outputs": [],
   "source": [
    "# Load saved tensor dataset\n",
    "'''\n",
    "For colab:\n",
    "'''\n",
    "train_dataset = torch.load(r'/content/gdrive/My Drive/APS360/Project/trainDataClass.pt')\n",
    "val_dataset = torch.load(r'/content/gdrive/My Drive/APS360/Project/valDataClass.pt')\n",
    "test_dataset = torch.load(r'/content/gdrive/My Drive/APS360/Project/testDataClass.pt')\n",
    "'''\n",
    "For local: (@Kevin)\n",
    "'''\n",
    "# train_dataset = torch.load(r'D:\\engsci\\year 3\\CLASS\\APS360\\project_pivot\\dataset\\Classes\\trainDataClass.pt')\n",
    "# val_dataset = torch.load(r'D:\\engsci\\year 3\\CLASS\\APS360\\project_pivot\\dataset\\Classes\\valDataClass.pt')\n",
    "# test_dataset = torch.load(r'D:\\engsci\\year 3\\CLASS\\APS360\\project_pivot\\dataset\\Classes\\testDataClass.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print stats from the dataset\n",
    "# for imgs, labels in torch.utils.data.DataLoader(train_dataset, batch_size=len(train_dataset), shuffle=True):\n",
    "# #     print(labels)\n",
    "#     labels = labels\n",
    "\n",
    "# hist_var = np.zeros((17))\n",
    "# for i in range(len(labels)):\n",
    "# #     print(labels[i].numpy())\n",
    "#     #Count each class samples...\n",
    "#     for j in range(0,17):\n",
    "#         if labels[i] == j:\n",
    "#             hist_var[j] += 1\n",
    "# print(hist_var) #Good visual for the demo! (see plot below :) )\n",
    "\n",
    "\n",
    "# plt.plot(np.linspace(0,16,17),hist_var,\"o\")\n",
    "# plt.ylabel('Number of Samples')\n",
    "# plt.xlabel('Class')\n",
    "# plt.title('TrainData Class Distributions')\n",
    "# plt.show()\n",
    "\n",
    "# for imgs, labels in torch.utils.data.DataLoader(val_dataset, batch_size=len(val_dataset), shuffle=True):\n",
    "# #     print(labels)\n",
    "#     labels = labels\n",
    "\n",
    "# hist_var = np.zeros((17))\n",
    "# for i in range(len(labels)):\n",
    "# #     print(labels[i].numpy())\n",
    "#     #Count each class samples...\n",
    "#     for j in range(0,17):\n",
    "#         if labels[i] == j:\n",
    "#             hist_var[j] += 1\n",
    "# print(hist_var) #Good visual for the demo! (see plot below :) )\n",
    "\n",
    "\n",
    "# plt.plot(np.linspace(0,16,17),hist_var,\"o\")\n",
    "# plt.ylabel('Number of Samples')\n",
    "# plt.xlabel('Class')\n",
    "# plt.title('valData Class Distributions')\n",
    "# plt.show()\n",
    "\n",
    "# for imgs, labels in torch.utils.data.DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=True):\n",
    "# #     print(labels)\n",
    "#     labels = labels\n",
    "\n",
    "# hist_var = np.zeros((17))\n",
    "# for i in range(len(labels)):\n",
    "# #     print(labels[i].numpy())\n",
    "#     #Count each class samples...\n",
    "#     for j in range(0,17):\n",
    "#         if labels[i] == j:\n",
    "#             hist_var[j] += 1\n",
    "# print(hist_var) #Good visual for the demo! (see plot below :) )\n",
    "\n",
    "\n",
    "# plt.plot(np.linspace(0,16,17),hist_var,\"o\")\n",
    "# plt.ylabel('Number of Samples')\n",
    "# plt.xlabel('Class')\n",
    "# plt.title('testData Class Distributions')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "WEJ4OXb67IUX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4. 1. 0. ... 5. 1. 7.]\n",
      "[0. 0. 0. ... 3. 0. 4.]\n",
      "[0. 2. 0. ... 1. 1. 2.]\n"
     ]
    }
   ],
   "source": [
    "# train_dataset = get_class_3(train_dataset,0,1,2)\n",
    "# val_dataset = get_class_3(val_dataset,0,1,2)\n",
    "# test_dataset = get_class_3(test_dataset,0,1,2)\n",
    "\n",
    "train_dataset = get_class(train_dataset)\n",
    "val_dataset = get_class(val_dataset)\n",
    "test_dataset = get_class(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "Hr_c4ReHx191"
   },
   "outputs": [],
   "source": [
    "use_cuda = True\n",
    "\n",
    "# For LSTM: https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html #torch.nn.LSTM \n",
    "# Hyperparameters\n",
    "N_FEATURES = 4\n",
    "N_CLASSES = 10\n",
    "N_HIDDEN = 64\n",
    "N_LAYERS = 11\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 200\n",
    "LEARNING_RATE = 1e-4\n",
    "LSTM_Net = LSTMClassifier(n_features=N_FEATURES, n_classes = N_CLASSES, n_hidden=N_HIDDEN, n_layers=N_LAYERS)\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "    LSTM_Net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y0RWdIsr-oLi",
    "outputId": "f98f71c5-86c2-44b9-a35f-326e6da2b249"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-3043df954e4f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_accs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_accs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLSTM_Net\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-24-48e974a4e3eb>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, train_dataset, val_dataset, num_epochs, batch_size, learning_rate)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m               \u001b[1;31m# backward pass (compute parameter updates)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m              \u001b[1;31m# make the updates for each parameter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m         \u001b[1;31m# a clean up step for PyTorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anacondainstal\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anacondainstal\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    117\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lr'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'weight_decay'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m                    \u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m                    )\n\u001b[0;32m    121\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anacondainstal\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\torch\\optim\\functional.py\u001b[0m in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[0;32m     92\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m             \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_losses, train_accs, val_losses, val_accs = train(LSTM_Net, train_dataset, val_dataset, num_epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, learning_rate=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "Ue6n6_07WJFW",
    "outputId": "2489c0d7-1818-496f-889f-9cc0f885a203"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot loss curves\n",
    "plot_training_curve(\"Loss\", train_losses, val_losses)\n",
    "\n",
    "# Plot accuracy curves\n",
    "plot_training_curve(\"Accuracy\", train_accs, val_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mtmDqDHmrSiD"
   },
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jOIt01mprSiD",
    "outputId": "d2e266f1-d4b8-42d3-b679-d90c77bda27a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Only run at the end...\n",
    "# test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# test_acc = get_accuracy(LSTM_Net, test_loader)\n",
    "# test_loss = get_loss(LSTM_Net, test_loader, criterion)\n",
    "\n",
    "# print((\"Test Loss: {:.4f}\").format(float(test_loss)))\n",
    "# print((\"Test Accuracy: {:.2f}%\").format(float(test_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Project_workbook_inst_classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
