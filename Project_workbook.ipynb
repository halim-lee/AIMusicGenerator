{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project File - APS360 Team 25\n",
    "Divided into the following section: \n",
    "# \n",
    "1) Library imports\n",
    "2) Data imports\n",
    "3) Model architecture definition\n",
    "4) Training function definition\n",
    "5) Model training\n",
    "6) Model testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library imports \n",
    "(Place all library imports here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KP - I just added the main ones from the labs.\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "#import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import time # Tracking model training time.\n",
    "\n",
    "#for Data importing\n",
    "import mido\n",
    "from mido import MidiFile, Message, MidiTrack, MetaMessage\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data imports\n",
    "#### MIDI reading functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CountTracks(directory):          #Count files and tracks in folder\n",
    "    trackCount = 0\n",
    "    fileCount = 0\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(\".midi\"):\n",
    "            fileCount += 1\n",
    "            midiDir = MidiFile(directory+\"/\"+file)\n",
    "            for track in midiDir.tracks:\n",
    "                trackCount += 1\n",
    "    print(fileCount+\" files\")\n",
    "    print(trackCount+\" tracks\")\n",
    "\n",
    "    \n",
    "def PrintMessages(mid):                # print midi messages\n",
    "    for i, track in enumerate(mid.tracks):\n",
    "        print('Track {}: {}'.format(i, track.name))\n",
    "        for msg in track:\n",
    "            print(msg)\n",
    "\n",
    "            \n",
    "def PrintSomeMessages(mid):             #print first 200 midi messages\n",
    "    track = mid.tracks[1]\n",
    "    for i,msg in enumerate(track):\n",
    "        if i < 200:\n",
    "            print(msg)\n",
    "            \n",
    "def PrintMetaMessages(mid):             #print fmeta messages\n",
    "    track = mid.tracks[0]\n",
    "    for i,msg in enumerate(track):\n",
    "        print(msg)\n",
    "\n",
    "def cleanupMessages(mid):              #removes non-note messages by force\n",
    "    track = mid.tracks[1]\n",
    "    track2 = []\n",
    "    for msg in track:\n",
    "        if msg.type == \"note_on\":\n",
    "            track2.append(msg)\n",
    "    mid.tracks[1] = track2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MIDI to Numpy code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Midi2NumpyNoSustain(mid):                                #converts to numpy array removing non-note messages\n",
    "    track = mid.tracks[1]                           #0th track only contains meta-messages, all notes on 1st track\n",
    "    notes = np.empty([0,4])\n",
    "    time = 0\n",
    "    for msg in track:\n",
    "        if msg.type == \"note_on\":                   # only count \"note\" messages - other inputs i.e. foot pedals are ignored\n",
    "            notes = np.append(notes,np.array([[msg.note, msg.velocity, msg.time + time, 0]]),axis=0)         # (note, velocity, time, sustain)\n",
    "            time = 0\n",
    "        else:\n",
    "            time += msg.time                        #adjust time when removing other messages\n",
    "    return notes\n",
    "\n",
    "\n",
    "def NumpyGetSustain(note):\n",
    "    notes = np.copy(note)\n",
    "    for i, msg in enumerate(notes):\n",
    "        if msg[1] > 0:                            # if velocity is not 0\n",
    "            j = 1\n",
    "            sustain = 0\n",
    "            while msg[0] != notes[i+j][0]:        # while note values are different\n",
    "                sustain += notes[i+j][2]\n",
    "                j += 1                            #search for next message with same note i.e. message telling that note was released\n",
    "            notes[i,3] = sustain + notes[i+j][2]\n",
    "    time = 0\n",
    "    for i, msg in enumerate(notes):\n",
    "        if msg[1] > 0:\n",
    "            notes[i,2] += time\n",
    "            time = 0\n",
    "        else:\n",
    "            time += msg[2]                        #adjust time\n",
    "    notes = notes[notes[:,1] > 0]                 #filter for notes with positive velocities (note presses)\n",
    "    return notes\n",
    "\n",
    "def NumpyNormalize(note, oneHot=False):                         #normalize all values to 0-1\n",
    "    notes = np.copy(note)\n",
    "    \n",
    "    if oneHot:\n",
    "        notes[:,12] /= 11\n",
    "        notes[:,13] /= 128\n",
    "        notes[:,14] /= 40000\n",
    "        notes[:,15] /= 40000\n",
    "    else:\n",
    "        notes[:,0] /= 128\n",
    "        notes[:,1] /= 128\n",
    "        notes[:,2] /= 40000\n",
    "        notes[:,3] /= 40000       \n",
    "    return notes\n",
    "\n",
    "def NumpyOneHot(note):\n",
    "    notes = np.copy(note)\n",
    "    oneHot = np.zeros([len(notes),16])\n",
    "    oneHot[:, 13:] = notes[:, 1:]\n",
    "    names = notes[:,0]\n",
    "    namesOct = names%12\n",
    "    oneHot[:,12] = (names-(namesOct))/12\n",
    "    \n",
    "    for i, name in enumerate(namesOct):\n",
    "        oneHot[i,name.astype(int)] = 1\n",
    "    \n",
    "    return oneHot\n",
    "\n",
    "def Midi2Numpy(path, oneHot=False): # full midi to numpy conversion\n",
    "    mid = MidiFile(path)\n",
    "    notes = Midi2NumpyNoSustain(mid)\n",
    "    cleanNotes = NumpyGetSustain(notes)\n",
    "    \n",
    "    if oneHot:\n",
    "        cleanNotes = NumpyOneHot(cleanNotes)\n",
    "    \n",
    "    normNotes = NumpyNormalize(cleanNotes, oneHot=oneHot)\n",
    "    return normNotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numpy to MIDI code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NumpyDenormalize(note): # interpret all values from 0-1 to normal values\n",
    "    notes = np.copy(note)    \n",
    "    if notes.shape[1] == 16: # if encode as one-hot\n",
    "        notes[:,12] *= 11\n",
    "        notes[:,13] *= 128\n",
    "        notes[:,14] *= 40000\n",
    "        notes[:,15] *= 40000\n",
    "        \n",
    "        notes = NumpyEncode(notes) #encode back as original 4-variable format\n",
    "    else:\n",
    "        notes[:,0] *= 128\n",
    "        notes[:,1] *= 128\n",
    "        notes[:,2] *= 40000\n",
    "        notes[:,3] *= 40000       \n",
    "    return notes.astype(int)\n",
    "\n",
    "def NumpyEncode(note): # convert back from one-hot encoding\n",
    "    notes = np.copy(note)\n",
    "    encoded = np.zeros([len(notes),4])\n",
    "    encoded[:, 1:] = notes[:, 13:]\n",
    "    encoded[:, 0] = notes[:,12]*12\n",
    "    \n",
    "    for i in range(len(notes)):\n",
    "        encoded[i,0] += np.argmax(notes[i,:12])\n",
    "    \n",
    "    return encoded\n",
    "\n",
    "def NumpySequence(notes): # put all notes into a \"timeline\" i.e.: time values of [10, 20, 10, 30] become [10, 30, 40, 70]\n",
    "    sequenced = np.copy(notes)                      # this allows us to easily add vel=0 notes in any order since we can later sort them by time\n",
    "    for i, msg in enumerate(sequenced):\n",
    "        if i > 0:\n",
    "            sequenced[i,2] += sequenced[i-1,2]\n",
    "    return sequenced\n",
    "\n",
    "def NumpyAddOffNotes(sequenced): # add vel=0 notes from sustain into sequenced timeline\n",
    "    withOff = np.copy(sequenced)\n",
    "    for msg in sequenced:\n",
    "        offNote = np.array([[msg[0], 0, msg[2] + msg[3], 0]])\n",
    "        withOff = np.append(withOff, offNote, axis=0)\n",
    "    #withOff = np.sort(withOff,axis=0)\n",
    "    withOff = withOff[withOff[:,2].argsort()] # sort by time\n",
    "    return withOff\n",
    "\n",
    "def NumpyUnsequence(notes): # revert time value to \"time since last message\"\n",
    "    unsequenced = np.copy(notes)\n",
    "    for i, msg in reversed(list(enumerate(unsequenced))):\n",
    "        unsequenced[i,3] = 0\n",
    "        if i > 0:\n",
    "            unsequenced[i,2] -= unsequenced[i-1,2]\n",
    "    return unsequenced\n",
    "\n",
    "def Numpy2MidiDirect(array):    #make MIDI object from numpy\n",
    "    #Start with initializing a new Mido Track:\n",
    "    mid = MidiFile()\n",
    "    track0 = MidiTrack()\n",
    "    track1 = MidiTrack()\n",
    "    \n",
    "    track0.append(MetaMessage('set_tempo', tempo=500000, time=0)) #MetaMessages not necessary but are present in used files\n",
    "    track0.append(MetaMessage('time_signature', numerator=4, denominator=4, clocks_per_click=24, notated_32nd_notes_per_beat=8, time=0))\n",
    "    track0.append(MetaMessage('end_of_track', time=1))\n",
    "    \n",
    "    track1.append(Message('program_change', channel=0, program=0, time=0))\n",
    "    \n",
    "    for i,note in enumerate(array):         # Get the index and the note. Array must be int array\n",
    "        j = 1\n",
    "        track1.append(Message('note_on',note = array[i,0], velocity = array[i,1],time = array[i,2])) # Add the note to the track.\n",
    "\n",
    "    mid.tracks.append(track0)\n",
    "    mid.tracks.append(track1)\n",
    "    return mid\n",
    "\n",
    "def Numpy2Midi(notes, name): # full numpy to midi conversion, saving result to [name].midi\n",
    "    denorm = NumpyDenormalize(notes)\n",
    "    seq = NumpySequence(denorm)\n",
    "    off = NumpyAddOffNotes(seq)\n",
    "    unseq = NumpyUnsequence(off)\n",
    "    mid = Numpy2MidiDirect(unseq)\n",
    "    mid.save(name + \".midi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generatng tensor dataset from CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Numpy2Dataset(notes,num=20,skip=10): # make list of sumpy arrays\n",
    "    samples = []\n",
    "    i = 0\n",
    "    while i+num <= len(notes):\n",
    "        samples.append(notes[i:i+num])\n",
    "        i += skip\n",
    "    return samples\n",
    "\n",
    "def SampleAllNumpy(dataPath): # generate samples from all saved CSVs\n",
    "    allSamples = []\n",
    "\n",
    "    for i,f in enumerate(os.listdir(dataPath)):\n",
    "        notes = np.genfromtxt(dataPath+f, delimiter=',')\n",
    "        allSamples += Numpy2Dataset(notes)\n",
    "        if i % 100 == 0:\n",
    "            print(i)\n",
    "    \n",
    "    return allSamples\n",
    "\n",
    "def SaveSamplesTensor(samples, outputPath): # save tensor\n",
    "    tens = torch.Tensor(samples)\n",
    "    torch.save(samples, outputPath+\"Notes_Dataset.pt\")\n",
    "    return tens   \n",
    "\n",
    "def SaveAllSamples(dataPath, outputPath): # save dataset tensor\n",
    "    samples = SampleAllNumpy(dataPath)\n",
    "    SaveSamplesTensor(samples, outputPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bulk data conversion code - COMMENT OUT IF NOT IN USE!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SaveAllSamples(\"data/numpy_files/\",\"data/\") #save all into tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: COMMENT OUT IF NOT IN USE TO AVOID ACCIDENTS!!!!!!!\n",
    "\n",
    "# Getting CSVs from MIDI data and processed data from CSVs\n",
    "# Processed MIDI does not contain program messages and so are a good measure of what output SHOULD look like in a perfect world\n",
    "\n",
    "# dataPath = \"data/MIDI_files_original/\"\n",
    "# outputPath = \"data/numpy_files/\"\n",
    "# processedPath = \"data/MIDI_files_processed/\"\n",
    "\n",
    "# for i,f in enumerate(os.listdir(dataPath)):\n",
    "#     notes = Midi2Numpy(dataPath+f)\n",
    "#     np.savetxt(outputPath + \"MIDI_{:04d}.csv\".format(i),notes,delimiter=\",\")\n",
    "#     Numpy2Midi(notes, processedPath + \"MIDI_{:04d}\".format(i))\n",
    "    \n",
    "#     if i % 100 == 0:\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataPath = \"data/numpy_files/\"  # one-hot encoding on CSVs\n",
    "# outputPath = \"data/numpy_onehot\"\n",
    "\n",
    "# for i,f in enumerate(os.listdir(dataPath)):\n",
    "#     notes = np.genfromtxt(dataPath+f, delimiter=',')\n",
    "#     notes = NumpyDenormalize(notes)\n",
    "#     notes = NumpyOneHot(notes)\n",
    "#     notes = NumpyNormalize(notes, oneHot=True)\n",
    "#     np.savetxt(outputPath + \"MIDI_{:04d}.csv\".format(i),notes,delimiter=\",\")\n",
    "#     if i % 100 == 0:\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model Code\n",
    "#### getting available notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetAllNotesMajor(root):# Get all used notes in major scale of root=root\n",
    "    notes = []\n",
    "    intervals = [2,2,1,2,2,2,1]\n",
    "    \n",
    "    while root > 24: #bring down to lowest used octave\n",
    "        root -= 12\n",
    "    \n",
    "    n = root\n",
    "    notes.append(n)\n",
    "    while n < 84: #up to higherst used note\n",
    "        for i in intervals:\n",
    "            n += i\n",
    "            notes.append(n)   \n",
    "    return notes    \n",
    "\n",
    "\n",
    "def GetRangeMajor(notes, low, high): # Get all notes within range\n",
    "    lowIndex = notes.index(low)\n",
    "    highIndex = notes.index(high)\n",
    "    \n",
    "    return notes[lowIndex:highIndex+1]   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Piece Class\n",
    "##### represents whole output from all 4 voices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Piece: # Entire baseline model compostion - composed of 4 voices soprano, alto, tenor, bass (SATB)\n",
    "    def __init__(self, barNum=16, root=60):# 16 bars in C major\n",
    "        self.root = root # root note\n",
    "        self.allNotes = GetAllNotesMajor(self.root) # all notes on major scale\n",
    "        self.barNum = barNum # number of bars\n",
    "        \n",
    "        self.soprano = Voice(self.allNotes,60,84,speed=8) # SATB\n",
    "        self.alto = Voice(self.allNotes,48,72)\n",
    "        self.tenor = Voice(self.allNotes,36,60)\n",
    "        self.bass = Voice(self.allNotes,24,48)\n",
    "          \n",
    "        self.notes = np.empty([0,4]) #notes output\n",
    "        \n",
    "        self.pieceChords = [] # chords\n",
    "        \n",
    "        self.chords = np.array([ # common classical C major chords\n",
    "            [ 0,  4,  7,  0],# I\n",
    "            [ 2,  5,  9,  2],# ii\n",
    "            [ 4,  7, 11,  4],# iii\n",
    "            [ 5,  9, 0,  5],# IV\n",
    "            [ 7, 11, 2,  7],# V\n",
    "            [ 9, 0, 4,  9],# vi\n",
    "            [11, 2, 5, 11],# vii dim\n",
    "            [ 2,  5,  9, 0],# ii7\n",
    "            [ 5,  9, 0, 4],# IVmaj7\n",
    "            [ 7, 11, 2, 5],# V7\n",
    "            [11, 2, 5, 9]])# vii7 half-dim\n",
    "        \n",
    "    def GenerateSoprano(self): # Generate soprano line\n",
    "        self.soprano.GenerateLine(self.soprano.speed*self.barNum)\n",
    "        \n",
    "    def GenerateAlto(self): # Generate alto line from chords\n",
    "        self.alto.GenerateChordLine(self.pieceChords)\n",
    "        \n",
    "    def GenerateTenor(self): # see alto\n",
    "        self.tenor.GenerateChordLine(self.pieceChords)\n",
    "        \n",
    "    def GenerateBass(self): # see alto\n",
    "        self.bass.GenerateChordLine(self.pieceChords)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def ChooseChord(self, sopNote): # Choose a fitting chord for soprano note\n",
    "        while sopNote >= 12:\n",
    "            sopNote -= 12\n",
    "        \n",
    "        goodChords = np.empty([0,4])\n",
    "        \n",
    "        for chord in self.chords:\n",
    "            if (chord==sopNote).sum() > 0:\n",
    "                goodChords = np.append(goodChords,[chord],axis=0)\n",
    "        \n",
    "        chosenChord = goodChords[random.randint(0,len(goodChords)-1)]\n",
    "        chosenChord = np.sort(np.unique(chosenChord))\n",
    "        \n",
    "        i = 12\n",
    "        chordNotes = chosenChord\n",
    "        while i < 120:\n",
    "            chordNotes = np.append(chordNotes, chosenChord+i)\n",
    "            i += 12\n",
    "        \n",
    "        return(chordNotes)\n",
    "    \n",
    "    def GetChords(self): # select all chords in piece\n",
    "        for i, note in enumerate(self.soprano.notes):\n",
    "            if i % 2 == 0:\n",
    "                sopNote = note[0]\n",
    "                chord = self.ChooseChord(sopNote)\n",
    "                self.pieceChords.append(chord)\n",
    "                \n",
    "    def Normalize(self): # normalize all values to 0-1\n",
    "        for i, msg in enumerate(self.notes):\n",
    "            self.notes[i,0] = msg[0]/128\n",
    "            self.notes[i,1] = msg[1]/128\n",
    "            self.notes[i,2] = msg[2]/40000\n",
    "            self.notes[i,3] = msg[3]/40000\n",
    "                \n",
    "    def GenerateLines(self): # Generate all SATB lines and joins them - entire baseline model\n",
    "        self.GenerateSoprano()\n",
    "        self.GetChords()\n",
    "        self.GenerateAlto()\n",
    "        self.GenerateTenor()\n",
    "        self.GenerateBass()\n",
    "        self.joinLines()\n",
    "        self.OffsetTime(20)\n",
    "        self.Normalize()\n",
    "        \n",
    "        return self.notes\n",
    "        \n",
    "    def InsertLine(self, starting, inserted, startIndex, skipIndex): # join 2 lines\n",
    "        base = np.copy(starting)\n",
    "        ins = np.copy(inserted)\n",
    "        \n",
    "        for i,note in enumerate(ins):\n",
    "            base = np.insert(base, (i*skipIndex)+startIndex, [note], axis=0)\n",
    "            \n",
    "        return base\n",
    "        \n",
    "    def joinLines(self): # join all SATB lines\n",
    "        #self.notes = np.copy(self.soprano)\n",
    "        self.notes = self.InsertLine(self.soprano.notes, self.alto.notes, 1, 3)\n",
    "        self.notes = self.InsertLine(self.notes, self.tenor.notes, 2, 4)\n",
    "        self.notes = self.InsertLine(self.notes, self.bass.notes, 3, 5)\n",
    "        \n",
    "    def OffsetTime(self, maxChange): # adds random time offsets to make output sound more organic\n",
    "        for note in self.notes:\n",
    "            note[2] += random.randint(0,maxChange)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Voice class\n",
    "##### Represents individual voices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Voice: # individual voices\n",
    "    def __init__(self, allNotes, lowNote, highNote, jump=3, speed=4, time=4096, velocity=64):\n",
    "        self.range = GetRangeMajor(allNotes,lowNote,highNote) #available ntoes\n",
    "        self.jump = jump #maximum pitch interval between notes\n",
    "        self.speed = speed #note length i.e. 4 for quarter, 8 for eighth etc.\n",
    "        self.time = time #song speed\n",
    "        self.velocity = velocity #note volume\n",
    "        self.notes = np.empty([0,4]) #notes output\n",
    "        self.lowNote = lowNote # lowest note\n",
    "        self.highNote = highNote # highest note\n",
    "        self.allNotes = allNotes # all notes in scale\n",
    "            \n",
    "        self.duration = self.time / self.speed # time between notes\n",
    "        \n",
    "        \n",
    "    def RandomStartNote(self): # Generate Random first note (for soprano)\n",
    "        note = random.choice(self.range)\n",
    "        self.notes = np.append(self.notes,np.array([[note, self.velocity, 0, self.duration]]),axis=0)\n",
    "        \n",
    "        \n",
    "    def RandomJump(self): # Generate Random next note (for soprano)\n",
    "        lastNote = self.notes[len(self.notes)-1][0] # find last played note\n",
    "        lastIndex = self.range.index(lastNote)\n",
    "        \n",
    "        newIndex = -1\n",
    "        while newIndex < 0 or newIndex >= len(self.range): # stay in range\n",
    "            newIndex = lastIndex + random.randint(-self.jump,self.jump)\n",
    "            \n",
    "        newNote = self.range[newIndex]\n",
    "        self.notes = np.append(self.notes,np.array([[newNote, self.velocity, self.duration, self.duration]]),axis=0)\n",
    "        \n",
    "        \n",
    "    def GenerateLine(self, length): # Generate random line (for soprano)\n",
    "        self.RandomStartNote()\n",
    "        \n",
    "        for n in range(length-1):\n",
    "            self.RandomJump()\n",
    "            \n",
    "            \n",
    "    def clearNotes(self):\n",
    "        self.notes = np.empty([0,4])\n",
    "        \n",
    "    def GetChordNotes(self, chordNotes): # Get useful notes from all chord notes\n",
    "        chordNotes = chordNotes[chordNotes >= self.lowNote]\n",
    "        chordNotes = chordNotes[chordNotes <= self.highNote]\n",
    "        return chordNotes\n",
    "    \n",
    "    def ChooseStartChordNote(self, chordNotes): # Choose Random note in chord\n",
    "        note = random.choice(chordNotes)\n",
    "        self.notes = np.append(self.notes,np.array([[note, self.velocity, 0, self.duration]]),axis=0)\n",
    "        \n",
    "    def ChooseChordNote(self,chordNotes): # Choose suitable next note in chord\n",
    "        lastNote = self.notes[len(self.notes)-1][0] # find last played note\n",
    "        \n",
    "        chordNotes = chordNotes[chordNotes >= lastNote - (self.jump*2)]\n",
    "        chordNotes = chordNotes[chordNotes <= lastNote + (self.jump*2)]\n",
    "        newNote = random.choice(chordNotes)\n",
    "        \n",
    "        self.notes = np.append(self.notes,np.array([[newNote, self.velocity, 0, self.duration]]),axis=0)\n",
    "        \n",
    "    def GenerateChordLine(self, chords): # Generate A/T/B lines\n",
    "        \n",
    "        firstChord = self.GetChordNotes(chords[0])\n",
    "        self.ChooseStartChordNote(firstChord)\n",
    "        \n",
    "        for c in chords[1:]:\n",
    "            chord = self.GetChordNotes(c)\n",
    "            self.ChooseChordNote(chord)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the hyperparameters below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For LSTM: https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html#torch.nn.LSTM \n",
    "n1 = 1 #Number of input features\n",
    "nh1 = 1 #Number of features in the hidden state h\n",
    "nl1 = 1 #Number of layers in each LSTM calling (more than 1 stacks them with same number of hidden features).\n",
    "dropout1 = 0 #Percentage dropout of each layer. I believe 0-->1 range.\n",
    "\n",
    "n2 = 1 #Number of input features\n",
    "nh2 = 1 #Number of features in the hidden state h\n",
    "nl2 = 1 #Number of layers in each LSTM calling (more than 1 stacks them with same number of hidden features).\n",
    "dropout2 = 0 #Percentage dropout of each layer. I believe 0-->1 range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1000) #Set the manual seed so that we get reproducible results.\n",
    "\n",
    "#Define the RNNMusicGenerator model below:\n",
    "class RNNMusicGenerator(nn.Module): \n",
    "    def __init__(self):\n",
    "        super(RNNMusicGenerator, self).__init__()\n",
    "        self.name = \"MusicGen\"\n",
    "        self.LSTM1 = nn.LSTM(input_size = n1, hidden_size = nh1,num_layers = nl1, batch_first = True,dropout = dropout1)\n",
    "        #^^Expects data as: (batch_size,sequence,features)\n",
    "        self.LSTM2 = nn.LSTM(input_size = n, hidden_size = nh,num_layers = nl, batch_first = True,dropout = dropout)\n",
    "        #unsure of the output dimensions still...\n",
    "    def forward(self, x):\n",
    "        x = (F.relu(self.LSTM1(x)))\n",
    "        x = self.LSTM2(x) #No activation function on second layer for now...\n",
    "        return x\n",
    "    \n",
    "print('Model class created succesfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To help us save the model easier...\n",
    "def get_model_name(name, batch_size, learning_rate, epoch):\n",
    "    \"\"\" Generate a name for the model consisting of all the hyperparameter values\n",
    "\n",
    "    Args:\n",
    "        config: Configuration object containing the hyperparameters\n",
    "    Returns:\n",
    "        path: A string with the hyperparameter name and value concatenated\n",
    "    \"\"\"\n",
    "    path = \"model_{0}_bs{1}_lr{2}_epoch{3}\".format(name,\n",
    "                                                   batch_size,\n",
    "                                                   learning_rate,\n",
    "                                                   epoch)\n",
    "    return path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,data, num_epochs=5, batch_size=64, learning_rate=1e-3):\n",
    "    torch.manual_seed(1000) #Fixed. Make sure we use this throughout...\n",
    "    criterion = nn.MSELoss() # mean square error loss. Compares reconstruction errors entry by entry.\n",
    "    optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                 lr=learning_rate, \n",
    "                                 weight_decay=1e-5) # <-- Sometimes Adam converges faster than SGD\n",
    "    train_loader = torch.utils.data.DataLoader(data, \n",
    "                                               batch_size=batch_size, \n",
    "                                               shuffle=True)\n",
    "    \n",
    "    iters, losses = [], []\n",
    "    \n",
    "    n = 0 # the number of iterations\n",
    "    start_time=time.time() #Start of training.\n",
    "    outputs = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for data in train_loader:\n",
    "            excerpt = data[:-1] # Extracts all but the last note (model will predict last note)\n",
    "            true_note = data[-1] # Extracts the last note.\n",
    "            pred_note = model(excerpt) # Collects next note prediction.\n",
    "            loss = criterion(pred_note, true_note)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad() # Clean up, clean up, everybody, everywhere...\n",
    "\n",
    "                \n",
    "            iters.append(n)\n",
    "            losses.append(float(loss)/batch_size)             # compute *average* loss\n",
    "            \n",
    "            n += 1\n",
    "        \n",
    "        print('Epoch:{}, Loss:{:.4f}'.format(epoch+1, float(loss)))\n",
    "        outputs.append((epoch, true_note, pred_note),)\n",
    "      #Checkpoint the model every epoch\n",
    "        model_path = get_model_name(model.name, batch_size, learning_rate, epoch) #Returns the model name for \n",
    "      #the save file.\n",
    "        print('model_path: ',model_path)\n",
    "        torch.save(model.state_dict(), model_path) #Saves the current model with the weights.\n",
    "        print('model checkpointed')\n",
    "    end_time= time.time()\n",
    "    \n",
    "    \n",
    "      # plotting\n",
    "    plt.title(\"Training Curve\")\n",
    "    plt.plot(iters, losses, label=\"Train\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNMusicGenerator()\n",
    "\n",
    "train(model,data,batch_size = 1,num_epochs = 1,lr = 0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our model is 'tested' with people listening to it, we need to just generate some samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using random noise inputs:\n",
    "\n",
    "x = torch.randn(1, 1, 1) # (Batch_size,sequence,notes) --> Must match the LSTM layer input.\n",
    "\n",
    "song_length = 1 #How many new notes we want the model to generate.\n",
    "\n",
    "start = True\n",
    "for t in range(0,song_length): #Generates t new notes.\n",
    "    new_sample = model(x)\n",
    "    if start:\n",
    "        new_excerpt = torch.cat(x,new_sample) #initializes new_excerpt as the random noise + new note\n",
    "    else:\n",
    "        new_excerpt = torch.cat(new_excerpt,new_sample)\n",
    "    x = torch.cat(x[1:],new_sample) #Update x by throwing out the first note in the sequence and shoving the new note to the end.\n",
    "\n",
    "print('loop done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
